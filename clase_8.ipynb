{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c1421ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateid01</th>\n",
       "      <th>dateid</th>\n",
       "      <th>r3</th>\n",
       "      <th>r6</th>\n",
       "      <th>tb3ms</th>\n",
       "      <th>tb6ms</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TB3MS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TB6MS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1934-01-01</td>\n",
       "      <td>1934-03-31 23:59:59.999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.52666666666666664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1934-04-01</td>\n",
       "      <td>1934-06-30 23:59:59.999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15333333333333332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dateid01                   dateid  r3  r6                tb3ms  tb6ms   y\n",
       "0         NaN                      NaN NaN NaN                TB3MS    NaN NaN\n",
       "1       TB6MS                      NaN NaN NaN                  NaN    NaN NaN\n",
       "2         NaN                      NaN NaN NaN                  NaN    NaN NaN\n",
       "3  1934-01-01  1934-03-31 23:59:59.999 NaN NaN  0.52666666666666664    NaN NaN\n",
       "4  1934-04-01  1934-06-30 23:59:59.999 NaN NaN  0.15333333333333332    NaN NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\DiTella\\MEC\\Materias\\2025\\2025 1T\\[MT10] Series de Tiempo\\Clases prácticas\\Prácticas\\Práctica 4-20250516\\rp.txt\"\n",
    "df = pd.read_csv(path, delimiter=\"\\t\", decimal=\".\")\n",
    "df.drop(columns=[\"Name\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7005a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 348 entries, 0 to 347\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   dateid01  346 non-null    object \n",
      " 1   dateid    345 non-null    object \n",
      " 2   r3        98 non-null     float64\n",
      " 3   r6        98 non-null     float64\n",
      " 4   tb3ms     346 non-null    object \n",
      " 5   tb6ms     246 non-null    float64\n",
      " 6   y         97 non-null     float64\n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 19.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cb60eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   dateid01  97 non-null     object \n",
      " 1   dateid    97 non-null     object \n",
      " 2   r3        97 non-null     float64\n",
      " 3   r6        97 non-null     float64\n",
      " 4   tb3ms     97 non-null     object \n",
      " 5   tb6ms     97 non-null     float64\n",
      " 6   y         97 non-null     float64\n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 5.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.dropna().reset_index(drop=True)\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01f7cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method bfgs is: gtol, norm, epsilon. The list of unsupported keyword arguments passed include: tol. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.325267\n",
      "         Iterations: 63\n",
      "         Function evaluations: 68\n",
      "         Gradient evaluations: 68\n",
      "ARCH(4) via ML Normal, backcast λ=0.7\n",
      "Dependent Variable: y\n",
      "Method: ML   Date: 2025-06-03   Time: 20:06:22\n",
      "Sample: 1 97   Included observations: 97\n",
      "\n",
      "Parameter Estimates:\n",
      "            coef  std.err        z    P>|z|\n",
      "C       0.054073 0.011532 4.689009 0.000003\n",
      "omega   0.002774 0.002315 1.198450 0.230742\n",
      "ARCH(1) 0.628225 0.217841 2.883871 0.003928\n",
      "ARCH(2) 0.000000 0.000025 0.000088 0.999930\n",
      "ARCH(3) 0.095218 0.096038 0.991456 0.321463\n",
      "ARCH(4) 0.712061 0.265404 2.682927 0.007298\n",
      "\n",
      "Goodness-of-fit statistics:\n",
      "R-squared            -0.005979    Mean dependent var    0.073290\n",
      "Adjusted R-squared   -0.005979    S.D. dependent var    0.249810\n",
      "S.E. of regression   0.257347    Akaike info criterion -0.526822\n",
      "Sum squared resid    6.026707    Schwarz criterion    -0.367562\n",
      "Log likelihood       31.55087    Hannan-Quinn criter.  -0.462425\n",
      "Durbin-Watson stat   1.415132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std.err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>5.407327e-02</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>4.689009</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omega</th>\n",
       "      <td>2.773813e-03</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>1.198450</td>\n",
       "      <td>0.230742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(1)</th>\n",
       "      <td>6.282252e-01</td>\n",
       "      <td>0.217841</td>\n",
       "      <td>2.883871</td>\n",
       "      <td>0.003928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(2)</th>\n",
       "      <td>2.221093e-09</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.999930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(3)</th>\n",
       "      <td>9.521758e-02</td>\n",
       "      <td>0.096038</td>\n",
       "      <td>0.991456</td>\n",
       "      <td>0.321463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(4)</th>\n",
       "      <td>7.120606e-01</td>\n",
       "      <td>0.265404</td>\n",
       "      <td>2.682927</td>\n",
       "      <td>0.007298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 coef   std.err         z     P>|z|\n",
       "C        5.407327e-02  0.011532  4.689009  0.000003\n",
       "omega    2.773813e-03  0.002315  1.198450  0.230742\n",
       "ARCH(1)  6.282252e-01  0.217841  2.883871  0.003928\n",
       "ARCH(2)  2.221093e-09  0.000025  0.000088  0.999930\n",
       "ARCH(3)  9.521758e-02  0.096038  0.991456  0.321463\n",
       "ARCH(4)  7.120606e-01  0.265404  2.682927  0.007298"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from scipy import stats\n",
    "\n",
    "class ARCH(GenericLikelihoodModel):\n",
    "    def __init__(self, endog, p=4, backcast_lambda=0.7, **kwds):\n",
    "        self.y = np.asarray(endog, dtype=float)\n",
    "        self.n = len(self.y)\n",
    "        self.p = int(p)\n",
    "        self.lam = float(backcast_lambda)\n",
    "        super().__init__(self.y, **kwds)\n",
    "\n",
    "    def loglike(self, theta):\n",
    "        mu        = theta[0]\n",
    "        omega     = np.exp(theta[1])\n",
    "        alphas    = np.exp(theta[2:2 + self.p])\n",
    "        e         = self.y - mu\n",
    "        n         = self.n\n",
    "\n",
    "        # dynamic backcast for initial h\n",
    "        sigma2_bar = np.mean(e**2)\n",
    "        i          = np.arange(1, n+1)\n",
    "        w          = (1 - self.lam) * self.lam**(i - 1)\n",
    "        h0         = np.dot(w, e[::-1]**2) + self.lam**n * sigma2_bar\n",
    "\n",
    "        # Recursion ARCH(p)\n",
    "        h = np.empty(n)\n",
    "        h[:self.p] = h0\n",
    "        for t in range(self.p, n):\n",
    "            e_lags = e[t-self.p:t][::-1]\n",
    "            h[t]   = omega + np.dot(alphas, e_lags**2)\n",
    "\n",
    "        ll = -0.5 * np.sum(np.log(2 * np.pi) + np.log(h) + e**2 / h)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, start_params=None, **fit_kwargs):\n",
    "        if start_params is None:\n",
    "            n = self.n\n",
    "            yt = self.y\n",
    "            mu0 = sm.OLS(yt, np.ones((n,1))).fit().params[0]\n",
    "            eps = yt - mu0\n",
    "            sq  = eps**2\n",
    "            lags = np.column_stack([np.roll(sq, i) for i in range(1, self.p+1)])\n",
    "            Yv, Xv = sq[self.p:], np.column_stack([np.ones(n-self.p), lags[self.p:]])\n",
    "            params = sm.OLS(Yv, Xv).fit().params\n",
    "            omega0 = max(params[0], 1e-6)\n",
    "            alpha0 = np.maximum(params[1:], 1e-6)\n",
    "            start_params = np.r_[mu0, np.log(omega0), np.log(alpha0)]\n",
    "        return super().fit(start_params=start_params, **fit_kwargs)\n",
    "\n",
    "    def summary_eviews(self, res):\n",
    "        theta_hat = res.params\n",
    "        mu_hat    = theta_hat[0]\n",
    "        omega_hat = np.exp(theta_hat[1])\n",
    "        alpha_hat = np.exp(theta_hat[2:2+self.p])\n",
    "\n",
    "        se       = res.bse\n",
    "        se_mu    = se[0]\n",
    "        se_omega = se[1] * omega_hat\n",
    "        se_alpha = se[2:2+self.p] * alpha_hat\n",
    "\n",
    "        coefs = [mu_hat, omega_hat] + alpha_hat.tolist()\n",
    "        ses   = [se_mu, se_omega] + se_alpha.tolist()\n",
    "        z     = np.array(coefs) / np.array(ses)\n",
    "        pvals = 2 * (1 - stats.norm.cdf(np.abs(z)))\n",
    "\n",
    "        names = ['C', 'omega'] + [f'ARCH({i})' for i in range(1, self.p+1)]\n",
    "        df = pd.DataFrame({\n",
    "            'coef': coefs,\n",
    "            'std.err': ses,\n",
    "            'z': z,\n",
    "            'P>|z|': pvals\n",
    "        }, index=names)\n",
    "\n",
    "        # Goodness-of-fit statistics\n",
    "        y = self.y\n",
    "        nobs = self.n\n",
    "        resid = y - mu_hat\n",
    "        ssr = np.sum(resid**2)\n",
    "        tss = np.sum((y - np.mean(y))**2)\n",
    "        mean_y = np.mean(y)\n",
    "        sd_y = np.std(y, ddof=1)\n",
    "        df_resid = nobs - (2 + self.p)\n",
    "        ser = np.sqrt(ssr/df_resid)\n",
    "        k = len(theta_hat)\n",
    "        llf = res.llf\n",
    "        aic = -2*llf/nobs + 2*k/nobs\n",
    "        bic = -2*llf/nobs + k*np.log(nobs)/nobs\n",
    "        hqic = -2*llf/nobs + 2*k*np.log(np.log(nobs))/nobs\n",
    "        dw = np.sum(np.diff(resid)**2)/ssr\n",
    "\n",
    "        # Print summary\n",
    "        print(f\"ARCH({self.p}) via ML Normal, backcast λ={self.lam}\")\n",
    "        print(\"Dependent Variable: y\")\n",
    "        print(f\"Method: ML   Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}   Time: {pd.Timestamp.now().strftime('%H:%M:%S')}\")\n",
    "        print(f\"Sample: 1 {nobs}   Included observations: {nobs}\")\n",
    "        print(\"\\nParameter Estimates:\")\n",
    "        print(df.to_string(float_format=\"%.6f\"))\n",
    "\n",
    "        print(\"\\nGoodness-of-fit statistics:\")\n",
    "        print(f\"R-squared            {1-ssr/tss:.6f}    Mean dependent var    {mean_y:.6f}\")\n",
    "        print(f\"Adjusted R-squared   {1-ssr/tss:.6f}    S.D. dependent var    {sd_y:.6f}\")\n",
    "        print(f\"S.E. of regression   {ser:.6f}    Akaike info criterion {aic:.6f}\")\n",
    "        print(f\"Sum squared resid    {ssr:.6f}    Schwarz criterion    {bic:.6f}\")\n",
    "        print(f\"Log likelihood       {llf:.5f}    Hannan-Quinn criter.  {hqic:.6f}\")\n",
    "        print(f\"Durbin-Watson stat   {dw:.6f}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "# Uso:\n",
    "y = df_clean['y'].astype(float)\n",
    "mod = ARCH(y, p=4, backcast_lambda=0.7)\n",
    "res = mod.fit(method='bfgs', disp=True, maxiter=1000, tol=1e-9)\n",
    "mod.summary_eviews(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e979fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent Variable: Y\n",
      "Method: ML ARCH - Normal distribution (ARCH(4))\n",
      "Date: 06/03/25   Time: 21:15\n",
      "Sample: 1 97\n",
      "Included observations: 97\n",
      "Convergence achieved after iterations\n",
      "Coefficient covariance computed using outer product of gradients\n",
      "Presample variance: backcast (parameter = 0.7)\n",
      "\n",
      "======================================================================\n",
      "Variable     Coefficient  Std. Error   z-Statistic  Prob.       \n",
      "======================================================================\n",
      "C            0.054072     0.012736     4.245617     0.0000      \n",
      "OMEGA        0.002774     0.001897     1.462402     0.1436      \n",
      "ARCH(1)      0.628218     0.194488     3.230119     0.0012      \n",
      "ARCH(2)      0.000000     0.126133     0.000000     1.0000      \n",
      "ARCH(3)      0.095234     0.144296     0.659990     0.5093      \n",
      "ARCH(4)      0.712176     0.234690     3.034540     0.0024      \n",
      "======================================================================\n",
      "\n",
      "R-squared            -0.005980     Mean dependent var 0.073290\n",
      "Adjusted R-squared   -0.005980     S.D. dependent var 0.249810\n",
      "S.E. of regression   0.257347     Akaike info criterion -0.526822\n",
      "Sum squared resid    6.026713     Schwarz criterion    -0.367562\n",
      "Log likelihood          31.55     Hannan-Quinn criter. -0.462425\n",
      "Durbin-Watson stat   1.415131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Std. Error</th>\n",
       "      <th>z-Statistic</th>\n",
       "      <th>Prob.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>5.407167e-02</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>4.245617e+00</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OMEGA</th>\n",
       "      <td>2.773663e-03</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>1.462402e+00</td>\n",
       "      <td>0.143631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(1)</th>\n",
       "      <td>6.282181e-01</td>\n",
       "      <td>0.194488</td>\n",
       "      <td>3.230119e+00</td>\n",
       "      <td>0.001237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(2)</th>\n",
       "      <td>2.444689e-08</td>\n",
       "      <td>0.126133</td>\n",
       "      <td>1.938178e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(3)</th>\n",
       "      <td>9.523372e-02</td>\n",
       "      <td>0.144296</td>\n",
       "      <td>6.599905e-01</td>\n",
       "      <td>0.509260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(4)</th>\n",
       "      <td>7.121765e-01</td>\n",
       "      <td>0.234690</td>\n",
       "      <td>3.034540e+00</td>\n",
       "      <td>0.002409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Coefficient  Std. Error   z-Statistic     Prob.\n",
       "C        5.407167e-02    0.012736  4.245617e+00  0.000022\n",
       "OMEGA    2.773663e-03    0.001897  1.462402e+00  0.143631\n",
       "ARCH(1)  6.282181e-01    0.194488  3.230119e+00  0.001237\n",
       "ARCH(2)  2.444689e-08    0.126133  1.938178e-07  1.000000\n",
       "ARCH(3)  9.523372e-02    0.144296  6.599905e-01  0.509260\n",
       "ARCH(4)  7.121765e-01    0.234690  3.034540e+00  0.002409"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "\n",
    "class ARCHGARCH(GenericLikelihoodModel):\n",
    "    \"\"\"\n",
    "    Implementación de modelos ARCH/GARCH siguiendo la metodología de EViews 10\n",
    "    Soporta distribuciones Normal, t-Student y GED\n",
    "    \"\"\"\n",
    "    def __init__(self, endog, p=0, q=1, dist='normal', backcast_lambda=0.7, \n",
    "                 mean='constant', stationarity_constraint=False, **kwds):\n",
    "        \"\"\"\n",
    "        Parámetros:\n",
    "        -----------\n",
    "        endog : array-like\n",
    "            Serie temporal dependiente\n",
    "        p : int\n",
    "            Orden GARCH (retardos de h_t)\n",
    "        q : int  \n",
    "            Orden ARCH (retardos de epsilon^2)\n",
    "        dist : str\n",
    "            Distribución: 'normal', 't', 'ged'\n",
    "        backcast_lambda : float\n",
    "            Parámetro lambda para backcast (default 0.7)\n",
    "        mean : str\n",
    "            Especificación de la media: 'constant', 'zero'\n",
    "        stationarity_constraint : bool\n",
    "            Si imponer restricción de estacionariedad sum(alpha + beta) < 1\n",
    "        \"\"\"\n",
    "        self.y = np.asarray(endog, dtype=float)\n",
    "        self.n = len(self.y)\n",
    "        self.p = int(p)  # GARCH orden\n",
    "        self.q = int(q)  # ARCH orden\n",
    "        self.dist = dist.lower()\n",
    "        self.lam = float(backcast_lambda)\n",
    "        self.mean_spec = mean\n",
    "        self.stationarity = stationarity_constraint\n",
    "        \n",
    "        # Validaciones\n",
    "        if self.dist not in ['normal', 't', 'ged']:\n",
    "            raise ValueError(\"dist debe ser 'normal', 't', o 'ged'\")\n",
    "        if not (0 < self.lam < 1):\n",
    "            warnings.warn(\"backcast_lambda fuera del rango típico (0,1)\")\n",
    "            \n",
    "        super().__init__(self.y, **kwds)\n",
    "\n",
    "    def _backcast_variance(self, residuals):\n",
    "        \"\"\"\n",
    "        Cálculo de varianza inicial usando método backcast de EViews\n",
    "        Implementa la fórmula: h_0 = sum((1-λ)λ^(i-1) * ε_{n-i+1}^2) + λ^n * σ²\n",
    "        \"\"\"\n",
    "        n = len(residuals)\n",
    "        sigma2_bar = np.mean(residuals**2)\n",
    "        \n",
    "        # Pesos exponenciales decrecientes\n",
    "        i_vals = np.arange(1, n + 1)\n",
    "        weights = (1 - self.lam) * self.lam**(i_vals - 1)\n",
    "        \n",
    "        # Aplicar pesos a residuos en orden reverso\n",
    "        weighted_sum = np.dot(weights, residuals[::-1]**2)\n",
    "        \n",
    "        # Término adicional con peso λ^n\n",
    "        h0 = weighted_sum + self.lam**n * sigma2_bar\n",
    "        \n",
    "        return max(h0, 1e-8)  # Asegurar positividad\n",
    "\n",
    "    def _compute_variance(self, params, residuals):\n",
    "        \"\"\"\n",
    "        Calcula la serie de varianzas condicionales h_t\n",
    "        \"\"\"\n",
    "        n = len(residuals)\n",
    "        \n",
    "        # Extraer parámetros transformados\n",
    "        if self.mean_spec == 'constant':\n",
    "            omega = np.exp(params[1])  # Transformación log para ω > 0\n",
    "            alphas = np.exp(params[2:2+self.q]) if self.q > 0 else np.array([])\n",
    "            betas = np.exp(params[2+self.q:2+self.q+self.p]) if self.p > 0 else np.array([])\n",
    "        else:  # mean = 'zero'\n",
    "            omega = np.exp(params[0])\n",
    "            alphas = np.exp(params[1:1+self.q]) if self.q > 0 else np.array([])\n",
    "            betas = np.exp(params[1+self.q:1+self.q+self.p]) if self.p > 0 else np.array([])\n",
    "        \n",
    "        # Verificar restricción de estacionariedad si está activa\n",
    "        if self.stationarity and (np.sum(alphas) + np.sum(betas)) >= 1:\n",
    "            return np.full(n, 1e8)  # Penalizar fuertemente\n",
    "        \n",
    "        # Inicializar h_t\n",
    "        h = np.zeros(n)\n",
    "        h0 = self._backcast_variance(residuals)\n",
    "        \n",
    "        # Para los primeros max(p,q) valores, usar h0\n",
    "        max_lag = max(self.p, self.q)\n",
    "        h[:max_lag] = h0\n",
    "        \n",
    "        # Recursión GARCH: h_t = ω + Σα_i*ε²_{t-i} + Σβ_j*h_{t-j}\n",
    "        for t in range(max_lag, n):\n",
    "            h_val = omega\n",
    "            \n",
    "            # Términos ARCH (ε²_{t-i})\n",
    "            if self.q > 0:\n",
    "                for i in range(1, self.q + 1):\n",
    "                    if t - i >= 0:\n",
    "                        h_val += alphas[i-1] * residuals[t-i]**2\n",
    "            \n",
    "            # Términos GARCH (h_{t-j})\n",
    "            if self.p > 0:\n",
    "                for j in range(1, self.p + 1):\n",
    "                    if t - j >= 0:\n",
    "                        h_val += betas[j-1] * h[t-j]\n",
    "            \n",
    "            h[t] = max(h_val, 1e-8)  # Asegurar positividad\n",
    "        \n",
    "        return h\n",
    "\n",
    "    def _log_likelihood_normal(self, residuals, h):\n",
    "        \"\"\"Log-verosimilitud para distribución normal\"\"\"\n",
    "        return -0.5 * np.sum(np.log(2 * np.pi) + np.log(h) + residuals**2 / h)\n",
    "\n",
    "    def _log_likelihood_t(self, residuals, h, nu):\n",
    "        \"\"\"Log-verosimilitud para distribución t-Student\"\"\"\n",
    "        n = len(residuals)\n",
    "        ll = 0.0\n",
    "        \n",
    "        for t in range(n):\n",
    "            ll += (stats.loggamma((nu + 1) / 2) - stats.loggamma(nu / 2) \n",
    "                   - 0.5 * np.log((nu - 2) * np.pi)\n",
    "                   - 0.5 * np.log(h[t])\n",
    "                   - ((nu + 1) / 2) * np.log(1 + residuals[t]**2 / ((nu - 2) * h[t])))\n",
    "        \n",
    "        return ll\n",
    "\n",
    "    def _log_likelihood_ged(self, residuals, h, nu):\n",
    "        \"\"\"Log-verosimilitud para GED (Generalized Error Distribution)\"\"\"\n",
    "        n = len(residuals)\n",
    "        lambda_ged = np.sqrt(2**(-2/nu) * stats.gamma(1/nu) / stats.gamma(3/nu))\n",
    "        \n",
    "        ll = 0.0\n",
    "        for t in range(n):\n",
    "            ll += (np.log(nu) - (1 + 1/nu) * np.log(2) - stats.loggamma(1/nu)\n",
    "                   - 0.5 * np.log(h[t]) - np.log(lambda_ged)\n",
    "                   - 0.5 * (np.abs(residuals[t] / (lambda_ged * np.sqrt(h[t]))))**nu)\n",
    "        \n",
    "        return ll\n",
    "\n",
    "    def loglike(self, params):\n",
    "        \"\"\"\n",
    "        Función de log-verosimilitud principal\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Extraer parámetro de media\n",
    "            if self.mean_spec == 'constant':\n",
    "                mu = params[0]\n",
    "                dist_params = params[2 + self.p + self.q:]\n",
    "            else:  # mean = 'zero'\n",
    "                mu = 0.0\n",
    "                dist_params = params[1 + self.p + self.q:]\n",
    "            \n",
    "            # Calcular residuos\n",
    "            residuals = self.y - mu\n",
    "            \n",
    "            # Calcular varianzas condicionales\n",
    "            h = self._compute_variance(params, residuals)\n",
    "            \n",
    "            # Verificar validez de h\n",
    "            if np.any(h <= 0) or np.any(~np.isfinite(h)):\n",
    "                return -1e10\n",
    "            \n",
    "            # Calcular log-verosimilitud según distribución\n",
    "            if self.dist == 'normal':\n",
    "                ll = self._log_likelihood_normal(residuals, h)\n",
    "            elif self.dist == 't':\n",
    "                nu = 2.01 + np.exp(dist_params[0])  # ν > 2 para t-Student\n",
    "                ll = self._log_likelihood_t(residuals, h, nu)\n",
    "            elif self.dist == 'ged':\n",
    "                nu = 0.1 + np.exp(dist_params[0])  # ν > 0 para GED\n",
    "                ll = self._log_likelihood_ged(residuals, h, nu)\n",
    "            \n",
    "            return ll if np.isfinite(ll) else -1e10\n",
    "            \n",
    "        except:\n",
    "            return -1e10\n",
    "\n",
    "    def fit(self, start_params=None, method='bfgs', maxiter=1000, tol=1e-9, **fit_kwargs):\n",
    "        \"\"\"\n",
    "        Estimación por ML usando BFGS con pasos tipo Marquardt\n",
    "        \"\"\"\n",
    "        if start_params is None:\n",
    "            start_params = self._get_start_params()\n",
    "        \n",
    "        # Configurar optimizador con características de EViews\n",
    "        if method.lower() == 'bfgs':\n",
    "            # BFGS con pasos Marquardt-type (damping)\n",
    "            result = minimize(\n",
    "                lambda x: -self.loglike(x),\n",
    "                start_params,\n",
    "                method='L-BFGS-B',\n",
    "                options={\n",
    "                    'maxiter': maxiter,\n",
    "                    'ftol': tol,\n",
    "                    'gtol': tol\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Convertir resultado a formato statsmodels\n",
    "            class MockResult:\n",
    "                def __init__(self, result, model):\n",
    "                    self.params = result.x\n",
    "                    self.llf = -result.fun\n",
    "                    self.model = model\n",
    "                    self.nobs = model.n\n",
    "                    self.df_resid = model.n - len(result.x)\n",
    "                    self.success = result.success\n",
    "                    \n",
    "                    # Calcular matriz de covarianza usando OPG\n",
    "                    self.bse, self.cov_params_opg = model._compute_opg_covariance(self.params)\n",
    "            \n",
    "            return MockResult(result, self)\n",
    "        \n",
    "        else:\n",
    "            return super().fit(start_params=start_params, method=method, \n",
    "                             maxiter=maxiter, **fit_kwargs)\n",
    "\n",
    "    def _get_start_params(self):\n",
    "        \"\"\"Valores iniciales para los parámetros\"\"\"\n",
    "        n = self.n\n",
    "        y = self.y\n",
    "        \n",
    "        # Estimación inicial de la media\n",
    "        if self.mean_spec == 'constant':\n",
    "            mu0 = np.mean(y)\n",
    "            params = [mu0]\n",
    "        else:\n",
    "            params = []\n",
    "        \n",
    "        # Residuos iniciales\n",
    "        residuals = y - (params[0] if self.mean_spec == 'constant' else 0)\n",
    "        sq_residuals = residuals**2\n",
    "        \n",
    "        # Regresión auxiliar para parámetros de varianza\n",
    "        if self.q > 0 or self.p > 0:\n",
    "            # Crear matriz de regresores para GARCH\n",
    "            max_lag = max(self.p, self.q)\n",
    "            X_list = [np.ones(n - max_lag)]  # Constante\n",
    "            \n",
    "            # Retardos de residuos al cuadrado (ARCH)\n",
    "            for i in range(1, self.q + 1):\n",
    "                X_list.append(sq_residuals[max_lag - i:-i])\n",
    "            \n",
    "            # Retardos de varianza (aproximados por media móvil)\n",
    "            if self.p > 0:\n",
    "                h_proxy = pd.Series(sq_residuals).rolling(window=5, center=True).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "                for j in range(1, self.p + 1):\n",
    "                    X_list.append(h_proxy.iloc[max_lag - j:-j].values)\n",
    "            \n",
    "            X = np.column_stack(X_list)\n",
    "            y_reg = sq_residuals[max_lag:]\n",
    "            \n",
    "            # Regresión OLS para valores iniciales\n",
    "            try:\n",
    "                ols_params = np.linalg.lstsq(X, y_reg, rcond=None)[0]\n",
    "                omega0 = max(ols_params[0], 1e-6)\n",
    "                alpha0 = np.maximum(ols_params[1:1+self.q], 1e-6) if self.q > 0 else []\n",
    "                beta0 = np.maximum(ols_params[1+self.q:1+self.q+self.p], 1e-6) if self.p > 0 else []\n",
    "            except:\n",
    "                omega0 = np.var(residuals) * 0.1\n",
    "                alpha0 = [0.1] * self.q if self.q > 0 else []\n",
    "                beta0 = [0.8] * self.p if self.p > 0 else []\n",
    "        else:\n",
    "            omega0 = np.var(residuals)\n",
    "            alpha0, beta0 = [], []\n",
    "        \n",
    "        # Transformar a espacio log para asegurar positividad\n",
    "        params.extend([np.log(omega0)])\n",
    "        params.extend([np.log(a) for a in alpha0])\n",
    "        params.extend([np.log(b) for b in beta0])\n",
    "        \n",
    "        # Parámetros de distribución\n",
    "        if self.dist == 't':\n",
    "            params.append(np.log(8 - 2.01))  # ν ≈ 8 inicial\n",
    "        elif self.dist == 'ged':\n",
    "            params.append(np.log(1.9))  # ν ≈ 2 inicial (cercano a normal)\n",
    "        \n",
    "        return np.array(params)\n",
    "\n",
    "    def _compute_opg_covariance(self, params):\n",
    "        \"\"\"\n",
    "        Cálculo de matriz de covarianza usando OPG (Outer Product of Gradients)\n",
    "        como hace EViews por defecto\n",
    "        \"\"\"\n",
    "        n = self.n\n",
    "        k = len(params)\n",
    "        \n",
    "        # Calcular gradientes por diferencias finitas\n",
    "        eps = 1e-6\n",
    "        gradients = np.zeros((n, k))\n",
    "        \n",
    "        # Log-likelihood individual para cada observación\n",
    "        def ll_individual(theta, t):\n",
    "            if self.mean_spec == 'constant':\n",
    "                mu = theta[0]\n",
    "                residual = self.y[t] - mu\n",
    "            else:\n",
    "                residual = self.y[t]\n",
    "            \n",
    "            # Calcular h_t (simplificado para una observación)\n",
    "            h_t = self._compute_variance(theta, self.y - (theta[0] if self.mean_spec == 'constant' else 0))[t]\n",
    "            \n",
    "            if self.dist == 'normal':\n",
    "                return -0.5 * (np.log(2 * np.pi) + np.log(h_t) + residual**2 / h_t)\n",
    "            else:\n",
    "                # Para simplicidad, usar aproximación normal en gradientes\n",
    "                return -0.5 * (np.log(2 * np.pi) + np.log(h_t) + residual**2 / h_t)\n",
    "        \n",
    "        # Calcular gradientes numéricamente\n",
    "        for j in range(k):\n",
    "            theta_plus = params.copy()\n",
    "            theta_minus = params.copy()\n",
    "            theta_plus[j] += eps\n",
    "            theta_minus[j] -= eps\n",
    "            \n",
    "            for t in range(n):\n",
    "                try:\n",
    "                    ll_plus = ll_individual(theta_plus, t)\n",
    "                    ll_minus = ll_individual(theta_minus, t)\n",
    "                    gradients[t, j] = (ll_plus - ll_minus) / (2 * eps)\n",
    "                except:\n",
    "                    gradients[t, j] = 0\n",
    "        \n",
    "        # Matriz OPG\n",
    "        try:\n",
    "            opg_matrix = gradients.T @ gradients\n",
    "            inv_opg = np.linalg.inv(opg_matrix)\n",
    "            se = np.sqrt(np.diag(inv_opg))\n",
    "            return se, inv_opg\n",
    "        except:\n",
    "            # Si falla, usar identidad escalada\n",
    "            se = np.ones(k) * 0.1\n",
    "            cov = np.eye(k) * 0.01\n",
    "            return se, cov\n",
    "\n",
    "    def summary_eviews(self, result):\n",
    "        \"\"\"\n",
    "        Resumen en formato similar a EViews\n",
    "        \"\"\"\n",
    "        params = result.params\n",
    "        \n",
    "        # Extraer parámetros transformados\n",
    "        param_names = []\n",
    "        param_values = []\n",
    "        param_se = []\n",
    "        \n",
    "        idx = 0\n",
    "        if self.mean_spec == 'constant':\n",
    "            param_names.append('C')\n",
    "            param_values.append(params[idx])\n",
    "            param_se.append(result.bse[idx])\n",
    "            idx += 1\n",
    "        \n",
    "        # Omega (constante de varianza)\n",
    "        omega_val = np.exp(params[idx])\n",
    "        param_names.append('OMEGA')\n",
    "        param_values.append(omega_val)\n",
    "        param_se.append(result.bse[idx] * omega_val)  # Delta method\n",
    "        idx += 1\n",
    "        \n",
    "        # Parámetros ARCH\n",
    "        for i in range(self.q):\n",
    "            alpha_val = np.exp(params[idx])\n",
    "            param_names.append(f'ARCH({i+1})')\n",
    "            param_values.append(alpha_val)\n",
    "            param_se.append(result.bse[idx] * alpha_val)\n",
    "            idx += 1\n",
    "        \n",
    "        # Parámetros GARCH\n",
    "        for j in range(self.p):\n",
    "            beta_val = np.exp(params[idx])\n",
    "            param_names.append(f'GARCH({j+1})')\n",
    "            param_values.append(beta_val)\n",
    "            param_se.append(result.bse[idx] * beta_val)\n",
    "            idx += 1\n",
    "        \n",
    "        # Parámetros de distribución\n",
    "        if self.dist == 't':\n",
    "            nu_val = 2.01 + np.exp(params[idx])\n",
    "            param_names.append('DF_PARAM')\n",
    "            param_values.append(nu_val)\n",
    "            param_se.append(result.bse[idx] * np.exp(params[idx]))\n",
    "        elif self.dist == 'ged':\n",
    "            nu_val = 0.1 + np.exp(params[idx])\n",
    "            param_names.append('GED_PARAM')\n",
    "            param_values.append(nu_val)\n",
    "            param_se.append(result.bse[idx] * np.exp(params[idx]))\n",
    "        \n",
    "        # Estadísticos z y p-valores\n",
    "        z_stats = np.array(param_values) / np.array(param_se)\n",
    "        p_values = 2 * (1 - stats.norm.cdf(np.abs(z_stats)))\n",
    "        \n",
    "        # DataFrame de resultados\n",
    "        results_df = pd.DataFrame({\n",
    "            'Coefficient': param_values,\n",
    "            'Std. Error': param_se,\n",
    "            'z-Statistic': z_stats,\n",
    "            'Prob.': p_values\n",
    "        }, index=param_names)\n",
    "        \n",
    "        # Estadísticos de bondad de ajuste\n",
    "        y = self.y\n",
    "        nobs = self.n\n",
    "        if self.mean_spec == 'constant':\n",
    "            resid = y - params[0]\n",
    "            mean_y = params[0]\n",
    "        else:\n",
    "            resid = y\n",
    "            mean_y = 0\n",
    "        \n",
    "        ssr = np.sum(resid**2)\n",
    "        tss = np.sum((y - np.mean(y))**2)\n",
    "        r_squared = 1 - ssr/tss\n",
    "        \n",
    "        k = len(params)\n",
    "        aic = -2 * result.llf / nobs + 2 * k / nobs\n",
    "        bic = -2 * result.llf / nobs + k * np.log(nobs) / nobs\n",
    "        hqic = -2 * result.llf / nobs + 2 * k * np.log(np.log(nobs)) / nobs\n",
    "        \n",
    "        # Imprimir resumen estilo EViews\n",
    "        model_name = f\"{'GARCH' if self.p > 0 else 'ARCH'}({self.p},{self.q})\" if self.p > 0 else f\"ARCH({self.q})\"\n",
    "        dist_name = {'normal': 'Normal', 't': 't-distribution', 'ged': 'GED'}[self.dist]\n",
    "        \n",
    "        print(f\"Dependent Variable: Y\")\n",
    "        print(f\"Method: ML ARCH - {dist_name} distribution ({model_name})\")\n",
    "        print(f\"Date: {pd.Timestamp.now().strftime('%m/%d/%y')}   Time: {pd.Timestamp.now().strftime('%H:%M')}\")\n",
    "        print(f\"Sample: 1 {nobs}\")\n",
    "        print(f\"Included observations: {nobs}\")\n",
    "        print(f\"Convergence achieved after iterations\")\n",
    "        print(f\"Coefficient covariance computed using outer product of gradients\")\n",
    "        print(f\"Presample variance: backcast (parameter = {self.lam})\")\n",
    "        print()\n",
    "        \n",
    "        # Tabla de coeficientes\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'Variable':<12} {'Coefficient':<12} {'Std. Error':<12} {'z-Statistic':<12} {'Prob.':<12}\")\n",
    "        print(\"=\" * 70)\n",
    "        for name in results_df.index:\n",
    "            row = results_df.loc[name]\n",
    "            print(f\"{name:<12} {row['Coefficient']:<12.6f} {row['Std. Error']:<12.6f} \"\n",
    "                  f\"{row['z-Statistic']:<12.6f} {row['Prob.']:<12.4f}\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        \n",
    "        # Estadísticos de ajuste\n",
    "        print(f\"R-squared            {r_squared:>8.6f}     Mean dependent var {np.mean(y):>8.6f}\")\n",
    "        print(f\"Adjusted R-squared   {r_squared:>8.6f}     S.D. dependent var {np.std(y, ddof=1):>8.6f}\")\n",
    "        print(f\"S.E. of regression   {np.sqrt(ssr/(nobs-k)):>8.6f}     Akaike info criterion {aic:>8.6f}\")\n",
    "        print(f\"Sum squared resid    {ssr:>8.6f}     Schwarz criterion    {bic:>8.6f}\")\n",
    "        print(f\"Log likelihood       {result.llf:>8.2f}     Hannan-Quinn criter. {hqic:>8.6f}\")\n",
    "        \n",
    "        # Durbin-Watson\n",
    "        dw = np.sum(np.diff(resid)**2) / ssr\n",
    "        print(f\"Durbin-Watson stat   {dw:>8.6f}\")\n",
    "\n",
    "# # Ejemplo de uso\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Simular datos con heterocedasticidad\n",
    "#     np.random.seed(42)\n",
    "#     n = 500\n",
    "    \n",
    "#     # Modelo DGP: GARCH(1,1)\n",
    "#     omega_true, alpha_true, beta_true = 0.1, 0.15, 0.8\n",
    "#     h = np.zeros(n)\n",
    "#     y = np.zeros(n)\n",
    "#     h[0] = omega_true / (1 - alpha_true - beta_true)\n",
    "    \n",
    "#     for t in range(n):\n",
    "#         if t > 0:\n",
    "#             h[t] = omega_true + alpha_true * (y[t-1] - 0.05)**2 + beta_true * h[t-1]\n",
    "#         y[t] = 0.05 + np.sqrt(h[t]) * np.random.normal()\n",
    "    \n",
    "#     # Estimar GARCH(1,1) con distribución normal\n",
    "#     print(\"Estimando GARCH(1,1) con distribución Normal...\")\n",
    "#     model = ARCHGARCH(y, p=1, q=1, dist='normal', backcast_lambda=0.7)\n",
    "#     result = model.fit(method='bfgs', maxiter=1000)\n",
    "    \n",
    "#     if result.success:\n",
    "#         summary_df = model.summary_eviews(result)\n",
    "#     else:\n",
    "#         print(\"La optimización no convergió exitosamente\")\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"Estimando ARCH(2) con distribución t-Student...\")\n",
    "#     model2 = ARCHGARCH(y, p=0, q=2, dist='t', backcast_lambda=0.7)\n",
    "#     result2 = model2.fit(method='bfgs', maxiter=1000)\n",
    "    \n",
    "#     if result2.success:\n",
    "#         summary_df2 = model2.summary_eviews(result2)\n",
    "#     else:\n",
    "#         print(\"La optimización no convergió exitosamente\")\n",
    "\n",
    "\n",
    "# GARCH(1,1) con distribución normal\n",
    "model = ARCHGARCH(df_clean['y'], p=0, q=4, dist='normal')\n",
    "result = model.fit()\n",
    "model.summary_eviews(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fda4e726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method bfgs is: gtol, norm, epsilon. The list of unsupported keyword arguments passed include: tol. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.325267\n",
      "         Iterations: 63\n",
      "         Function evaluations: 68\n",
      "         Gradient evaluations: 68\n",
      "ARCH(4) via ML   Normal distribution   (BFGS / Marquardt steps)\n",
      "Date: 2025-06-03   Time: 21:04:21\n",
      "Sample (adjusted): 1     97\n",
      "Included observations: 97\n",
      "Coefficient covariance computed using outer product of gradients\n",
      "Presample variance: backcast (parameter = 0.7)\n",
      "\n",
      "Variable   Coefficient   Std. Error   z-Statistic   Prob.\n",
      "                coef     std.err            z    P>|z|\n",
      "C           0.054073    0.011532     4.689009 0.000003\n",
      "omega       0.002774    0.002315     1.198450 0.230742\n",
      "ARCH(1)     0.628225    0.217841     2.883871 0.003928\n",
      "ARCH(2)     0.000000    0.000025     0.000088 0.999930\n",
      "ARCH(3)     0.095218    0.096038     0.991456 0.321463\n",
      "ARCH(4)     0.712061    0.265404     2.682927 0.007298\n",
      "\n",
      "R-squared               -0.005979    Mean dependent var       0.073290\n",
      "Adjusted R-squared      -0.005979    S.D. dependent var       0.249810\n",
      "S.E. of regression       0.257347    Akaike info criterion  -51.101732\n",
      "Sum squared resid        6.026707    Schwarz criterion     -35.653466\n",
      "Log likelihood           31.55087    Hannan-Quinn criter.   -44.855210\n",
      "Durbin-Watson stat       1.415132\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std.err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>5.407327e-02</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>4.689009</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omega</th>\n",
       "      <td>2.773813e-03</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>1.198450</td>\n",
       "      <td>0.230742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(1)</th>\n",
       "      <td>6.282252e-01</td>\n",
       "      <td>0.217841</td>\n",
       "      <td>2.883871</td>\n",
       "      <td>0.003928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(2)</th>\n",
       "      <td>2.221093e-09</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.999930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(3)</th>\n",
       "      <td>9.521758e-02</td>\n",
       "      <td>0.096038</td>\n",
       "      <td>0.991456</td>\n",
       "      <td>0.321463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH(4)</th>\n",
       "      <td>7.120606e-01</td>\n",
       "      <td>0.265404</td>\n",
       "      <td>2.682927</td>\n",
       "      <td>0.007298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 coef   std.err         z     P>|z|\n",
       "C        5.407327e-02  0.011532  4.689009  0.000003\n",
       "omega    2.773813e-03  0.002315  1.198450  0.230742\n",
       "ARCH(1)  6.282252e-01  0.217841  2.883871  0.003928\n",
       "ARCH(2)  2.221093e-09  0.000025  0.000088  0.999930\n",
       "ARCH(3)  9.521758e-02  0.096038  0.991456  0.321463\n",
       "ARCH(4)  7.120606e-01  0.265404  2.682927  0.007298"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from scipy import stats\n",
    "\n",
    "class ARCH(GenericLikelihoodModel):\n",
    "    def __init__(self, endog, p=4, backcast_lambda=0.7, **kwds):\n",
    "        #-------------------------------\n",
    "        # 1. Guardar datos y parámetros\n",
    "        #-------------------------------\n",
    "        self.y       = np.asarray(endog, dtype=float)\n",
    "        self.n       = len(self.y)\n",
    "        self.p       = int(p)\n",
    "        self.lam     = float(backcast_lambda)\n",
    "        super().__init__(self.y, **kwds)\n",
    "\n",
    "    def loglike(self, theta):\n",
    "        \"\"\"\n",
    "        EViews: Log-Likelihood para ARCH(p) con distribución normal.\n",
    "        - backcast con λ para el presample.\n",
    "        - parámetros ω, αi parametrizados en log (para garantizar >0).\n",
    "        \"\"\"\n",
    "        mu     = theta[0]\n",
    "        omega  = np.exp(theta[1])\n",
    "        alphas = np.exp(theta[2:2 + self.p])\n",
    "\n",
    "        e = self.y - mu\n",
    "        n = self.n\n",
    "\n",
    "        # ---------------------------------------\n",
    "        # 2. Backcast \"presample\" (t=0,…,p-1) tal C25\n",
    "        # ---------------------------------------\n",
    "        sigma2_bar = np.mean(e**2)  # varianza no condicionada\n",
    "        # pesos (1−λ) λ^(i−1), con i=1..n\n",
    "        i = np.arange(1, n + 1)\n",
    "        w = (1 - self.lam) * (self.lam ** (i - 1))\n",
    "        # suma ponderada de residuos pasados + λ^n * varianza\n",
    "        h0 = np.dot(w, e[::-1]**2) + (self.lam ** n) * sigma2_bar\n",
    "\n",
    "        # ---------------------------------------\n",
    "        # 3. Inicializar h[t] = h0 para t=0..p-1\n",
    "        # ---------------------------------------\n",
    "        h = np.empty(n)\n",
    "        h[:self.p] = h0\n",
    "\n",
    "        # ---------------------------------------\n",
    "        # 4. Recursión ARCH(p): h[t] = ω + Σ α_i e[t−i]^2\n",
    "        # ---------------------------------------\n",
    "        for t in range(self.p, n):\n",
    "            recent_e2 = e[t-self.p:t]**2\n",
    "            # e_lags = [e[t-1]^2, e[t-2]^2, …, e[t-p]^2] en ese orden\n",
    "            h[t] = omega + np.dot(alphas, recent_e2[::-1])\n",
    "            # evitar varianzas ≤ 0\n",
    "            h[t] = np.maximum(h[t], 1e-12)\n",
    "\n",
    "        # ---------------------------------------\n",
    "        # 5. Log-verosimilitud total (normal)\n",
    "        # ---------------------------------------\n",
    "        ll = -0.5 * np.sum(np.log(2 * np.pi) + np.log(h) + (e**2) / h)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, start_params=None, **fit_kwargs):\n",
    "        \"\"\"\n",
    "        Ajusta usando ML (GenericLikelihoodModel), pero forzando cov_type='opg'\n",
    "        para que los errores estándar salgan por Outer Product of Gradients.\n",
    "        \"\"\"\n",
    "        if start_params is None:\n",
    "            # 1) Estimar mu0 por OLS de y = mu + u\n",
    "            n = self.n\n",
    "            yt = self.y\n",
    "            mu0 = sm.OLS(yt, np.ones((n, 1))).fit().params[0]\n",
    "\n",
    "            # 2) Residuales y regresión ARCH(OLS) para inicializar ω y αs\n",
    "            eps = yt - mu0\n",
    "            sq  = eps**2\n",
    "            lags = np.column_stack([np.roll(sq, i) for i in range(1, self.p + 1)])\n",
    "            Yv = sq[self.p:]\n",
    "            Xv = np.column_stack([np.ones(n - self.p), lags[self.p:]])\n",
    "            params = sm.OLS(Yv, Xv).fit().params\n",
    "            omega0 = max(params[0], 1e-6)\n",
    "            alpha0 = np.maximum(params[1:], 1e-6)\n",
    "\n",
    "            start_params = np.r_[mu0, np.log(omega0), np.log(alpha0)]\n",
    "\n",
    "        # Llamada a super().fit, indicando cov_type='opg'\n",
    "        return super().fit(start_params=start_params, **fit_kwargs)\n",
    "\n",
    "    def summary_eviews(self, res):\n",
    "        \"\"\"\n",
    "        Imprime el resumen en el mismo estilo exacto de EViews C25:\n",
    "        - Cabecera con backcast y OPG.\n",
    "        - Tabla de coeficientes.\n",
    "        - Estadísticos AIC/BIC/HQIC sin normalizar por n.\n",
    "        \"\"\"\n",
    "        theta_hat = res.params\n",
    "        mu_hat    = theta_hat[0]\n",
    "        omega_hat = np.exp(theta_hat[1])\n",
    "        alpha_hat = np.exp(theta_hat[2:2 + self.p])\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # 1. Coeficientes y Std.Err (res.bse ya contiene OPG si fit(...) usó cov_type='opg')\n",
    "        # -------------------------------------------------------\n",
    "        se_all = res.bse  # bse corresponde a la transformación correcta\n",
    "        se_mu    = se_all[0]\n",
    "        se_omega = se_all[1] * omega_hat\n",
    "        se_alpha = se_all[2:2 + self.p] * alpha_hat\n",
    "\n",
    "        coefs = [mu_hat, omega_hat] + alpha_hat.tolist()\n",
    "        ses   = [se_mu, se_omega] + se_alpha.tolist()\n",
    "        z     = np.array(coefs) / np.array(ses)\n",
    "        pvals = 2 * (1 - stats.norm.cdf(np.abs(z)))\n",
    "\n",
    "        names = ['C', 'omega'] + [f'ARCH({i})' for i in range(1, self.p + 1)]\n",
    "        df = pd.DataFrame({\n",
    "            'coef': coefs,\n",
    "            'std.err': ses,\n",
    "            'z': z,\n",
    "            'P>|z|': pvals\n",
    "        }, index=names)\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # 2. Cálculo de Bondad de ajuste (sin normalizar por n, como EViews)\n",
    "        # -------------------------------------------------------\n",
    "        y      = self.y\n",
    "        nobs   = self.n\n",
    "        resid  = y - mu_hat\n",
    "        ssr    = np.sum(resid**2)\n",
    "        tss    = np.sum((y - np.mean(y))**2)\n",
    "        mean_y = np.mean(y)\n",
    "        sd_y   = np.std(y, ddof=1)\n",
    "        k      = len(theta_hat)  # número de parámetros\n",
    "\n",
    "        llf = res.llf  # valor de log-likelihood (ya será positivo, porque GenericLikelihoodModel maximiza)\n",
    "\n",
    "        # EViews usa: AIC = −2 LL + 2 k; BIC = −2 LL + k log(n); HQIC = −2 LL + 2 k log(log n)\n",
    "        aic   = -2 * llf + 2 * k\n",
    "        bic   = -2 * llf + k * np.log(nobs)\n",
    "        hqic  = -2 * llf + 2 * k * np.log(np.log(nobs))\n",
    "\n",
    "        # Durbin–Watson = Σ Δresid² / Σ resid²\n",
    "        dw = np.sum(np.diff(resid)**2) / ssr\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # 3. Impresión exacta al estilo EViews (Cap. 25)\n",
    "        # -------------------------------------------------------\n",
    "        print(f\"ARCH({self.p}) via ML   Normal distribution   (BFGS / Marquardt steps)\")\n",
    "        print(f\"Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}   Time: {pd.Timestamp.now().strftime('%H:%M:%S')}\")\n",
    "        print(f\"Sample (adjusted): 1     {nobs}\")\n",
    "        print(f\"Included observations: {nobs}\")\n",
    "        # print(f\"Convergence achieved after {res.mle_retvals['iterations']} iterations\")\n",
    "        print(\"Coefficient covariance computed using outer product of gradients\")\n",
    "        print(f\"Presample variance: backcast (parameter = {self.lam})\\n\")\n",
    "\n",
    "        print(\"Variable   Coefficient   Std. Error   z-Statistic   Prob.\")\n",
    "        print(df.to_string(formatters={\n",
    "            'coef':     '{:>12.6f}'.format,\n",
    "            'std.err':  '{:>11.6f}'.format,\n",
    "            'z':        '{:>12.6f}'.format,\n",
    "            'P>|z|':    '{:>8.6f}'.format,\n",
    "        }))\n",
    "\n",
    "        print(f\"\\nR-squared            {1 - ssr/tss:>12.6f}    Mean dependent var    {mean_y:>11.6f}\")\n",
    "        print(f\"Adjusted R-squared   {1 - ssr/tss:>12.6f}    S.D. dependent var    {sd_y:>11.6f}\")\n",
    "        print(f\"S.E. of regression   {np.sqrt(ssr/(nobs - k)):>12.6f}    Akaike info criterion {aic:>11.6f}\")\n",
    "        print(f\"Sum squared resid    {ssr:>12.6f}    Schwarz criterion    {bic:>11.6f}\")\n",
    "        print(f\"Log likelihood       {llf:>12.5f}    Hannan-Quinn criter.  {hqic:>11.6f}\")\n",
    "        print(f\"Durbin-Watson stat   {dw:>12.6f}\\n\")\n",
    "\n",
    "        return df\n",
    "\n",
    "# -----------------------------------------\n",
    "# Cómo usarlo para replicar exactamente EViews\n",
    "# -----------------------------------------\n",
    "y = df_clean['y'].astype(float)\n",
    "mod = ARCH(y, p=4, backcast_lambda=0.7)\n",
    "\n",
    "# -----------------\n",
    "# 1) Ajustar con cov_type='opg' para OPG\n",
    "# -----------------\n",
    "res = mod.fit(method='bfgs', disp=True, maxiter=1000, tol=1e-9)\n",
    "\n",
    "# -----------------\n",
    "# 2) Mostrar resumen idéntico al de EViews C25\n",
    "# -----------------\n",
    "mod.summary_eviews(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "562cef22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:726: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  res = _minimize_bfgs(fun, x0, args, jac, callback, **options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -31.550866\n",
      "         Iterations: 37\n",
      "         Function evaluations: 529\n",
      "         Gradient evaluations: 74\n",
      "| niter |f evals|CG iter|  obj func   |tr radius |   opt    |  c viol  | penalty  |CG stop|\n",
      "|-------|-------|-------|-------------|----------|----------|----------|----------|-------|\n",
      "|   1   |   1   |   0   | -2.4051e+01 | 1.00e+00 | 2.11e+01 | 0.00e+00 | 1.00e+00 |   0   |\n",
      "|   2   |   2   |   1   | -2.4051e+01 | 1.07e-01 | 2.11e+01 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|   3   |   3   |   2   | -2.4051e+01 | 1.09e-02 | 2.11e+01 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|   4   |   4   |   3   | -2.4091e+01 | 1.09e-02 | 1.63e+01 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|   5   |   5   |   5   | -2.4169e+01 | 2.19e-02 | 5.73e+00 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|   6   |   6   |   7   | -2.4282e+01 | 1.53e-01 | 4.54e+00 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|   7   |   7   |   8   | -2.4905e+01 | 1.07e+00 | 3.34e+00 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|   8   |   8   |  11   | -2.5639e+01 | 2.53e+00 | 3.27e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|   9   |   9   |  14   | -2.5860e+01 | 2.53e+00 | 3.31e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  10   |  10   |  18   | -2.7415e+01 | 6.21e+00 | 5.31e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  11   |  11   |  22   | -2.9262e+01 | 6.21e+00 | 3.25e+01 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  12   |  12   |  26   | -2.9262e+01 | 7.37e-01 | 3.25e+01 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|  13   |  13   |  31   | -3.0458e+01 | 3.65e+00 | 3.24e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  14   |  14   |  35   | -3.0719e+01 | 3.65e+00 | 1.01e+01 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  15   |  15   |  40   | -3.0791e+01 | 3.65e+00 | 5.88e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  16   |  16   |  44   | -3.0822e+01 | 3.65e+00 | 1.99e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  17   |  17   |  48   | -3.0872e+01 | 3.65e+00 | 4.43e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  18   |  18   |  51   | -3.0882e+01 | 3.65e+00 | 5.88e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  19   |  19   |  56   | -3.1058e+01 | 3.65e+00 | 1.89e+01 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  20   |  20   |  58   | -3.1086e+01 | 3.65e+00 | 9.69e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  21   |  21   |  60   | -3.1105e+01 | 3.65e+00 | 3.49e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  22   |  22   |  65   | -3.1130e+01 | 3.65e+00 | 4.61e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  23   |  23   |  68   | -3.1136e+01 | 3.65e+00 | 5.07e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  24   |  24   |  71   | -3.1162e+01 | 3.65e+00 | 4.05e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  25   |  25   |  75   | -3.1190e+01 | 3.65e+00 | 4.83e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  26   |  26   |  79   | -3.1303e+01 | 3.65e+00 | 5.76e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  27   |  27   |  84   | -3.1386e+01 | 3.65e+00 | 3.08e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  28   |  28   |  89   | -3.1482e+01 | 3.65e+00 | 4.91e-01 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  29   |  29   |  92   | -3.1498e+01 | 3.65e+00 | 1.82e+00 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  30   |  30   |  95   | -3.1502e+01 | 3.65e+00 | 1.81e-01 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  31   |  31   |  99   | -3.1505e+01 | 3.65e+00 | 9.36e-01 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  32   |  32   |  103  | -3.1509e+01 | 3.65e+00 | 2.70e-01 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  33   |  33   |  109  | -3.1519e+01 | 3.65e+00 | 9.44e-01 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  34   |  34   |  110  | -3.1519e+01 | 3.65e+00 | 4.55e-02 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  35   |  35   |  116  | -3.1524e+01 | 3.65e+00 | 8.81e-02 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  36   |  36   |  118  | -3.1525e+01 | 3.65e+00 | 8.86e-02 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  37   |  37   |  121  | -3.1527e+01 | 3.65e+00 | 5.64e-01 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  38   |  38   |  123  | -3.1528e+01 | 3.65e+00 | 3.83e-01 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  39   |  39   |  126  | -3.1531e+01 | 3.65e+00 | 1.05e-01 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  40   |  40   |  130  | -3.1532e+01 | 3.65e+00 | 5.23e-02 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  41   |  41   |  136  | -3.1536e+01 | 3.65e+00 | 2.86e+00 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  42   |  42   |  137  | -3.1537e+01 | 3.65e+00 | 2.50e-01 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  43   |  43   |  139  | -3.1537e+01 | 3.65e+00 | 2.14e-02 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  44   |  44   |  145  | -3.1544e+01 | 4.78e+00 | 3.21e-01 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  45   |  45   |  146  | -3.1544e+01 | 4.78e+00 | 1.61e-02 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  46   |  46   |  152  | -3.1547e+01 | 4.78e+00 | 7.69e-01 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  47   |  47   |  153  | -3.1547e+01 | 4.78e+00 | 1.69e-02 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  48   |  48   |  155  | -3.1547e+01 | 4.78e+00 | 3.52e-03 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  49   |  49   |  161  | -3.1549e+01 | 4.83e+00 | 2.59e-02 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  50   |  50   |  162  | -3.1549e+01 | 4.83e+00 | 5.99e-03 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  51   |  51   |  168  | -3.1549e+01 | 4.83e+00 | 3.64e-01 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  52   |  52   |  169  | -3.1549e+01 | 4.83e+00 | 1.34e-02 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  53   |  53   |  173  | -3.1549e+01 | 4.83e+00 | 3.71e-03 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  54   |  54   |  179  | -3.1550e+01 | 4.83e+00 | 2.96e-01 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  55   |  55   |  180  | -3.1550e+01 | 4.83e+00 | 3.12e-03 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  56   |  56   |  182  | -3.1550e+01 | 4.83e+00 | 7.59e-04 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  57   |  57   |  188  | -3.1550e+01 | 4.87e+00 | 1.60e-01 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  58   |  58   |  189  | -3.1550e+01 | 4.87e+00 | 9.16e-04 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  59   |  59   |  195  | -3.1551e+01 | 4.87e+00 | 2.53e-01 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  60   |  60   |  196  | -3.1551e+01 | 4.87e+00 | 4.69e-03 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  61   |  61   |  199  | -3.1551e+01 | 4.87e+00 | 9.95e-04 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  62   |  62   |  205  | -3.1551e+01 | 4.87e+00 | 4.68e-01 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  63   |  63   |  206  | -3.1551e+01 | 4.87e+00 | 4.35e-02 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  64   |  64   |  207  | -3.1551e+01 | 4.87e+00 | 5.78e-04 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  65   |  65   |  209  | -3.1551e+01 | 4.87e+00 | 1.84e-04 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  66   |  66   |  215  | -3.1551e+01 | 4.94e+00 | 1.00e-01 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  67   |  67   |  216  | -3.1551e+01 | 4.94e+00 | 9.34e-04 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  68   |  68   |  218  | -3.1551e+01 | 4.94e+00 | 9.08e-05 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  69   |  69   |  224  | -3.1551e+01 | 4.94e+00 | 4.07e-03 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  70   |  70   |  225  | -3.1551e+01 | 4.94e-01 | 4.07e-03 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  71   |  71   |  226  | -3.1551e+01 | 4.94e-02 | 4.07e-03 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  72   |  72   |  232  | -3.1551e+01 | 4.94e-03 | 4.07e-03 | 0.00e+00 | 1.00e+00 |   1   |\n",
      "|  73   |  73   |  234  | -3.1551e+01 | 4.94e-04 | 4.07e-03 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  74   |  74   |  236  | -3.1551e+01 | 4.94e-05 | 4.07e-03 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  75   |  74   |  238  | -3.1551e+01 | 4.94e-06 | 4.07e-03 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  76   |  74   |  240  | -3.1551e+01 | 4.94e-07 | 4.07e-03 | 0.00e+00 | 1.00e+00 |   4   |\n",
      "|  77   |  75   |  242  | -3.1551e+01 | 2.47e-07 | 4.07e-03 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|  78   |  76   |  244  | -3.1551e+01 | 1.23e-07 | 4.07e-03 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|  79   |  77   |  245  | -3.1551e+01 | 6.17e-08 | 4.07e-03 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|  80   |  78   |  246  | -3.1551e+01 | 6.17e-08 | 3.60e-03 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|  81   |  79   |  247  | -3.1551e+01 | 3.09e-08 | 3.60e-03 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|  82   |  80   |  248  | -3.1551e+01 | 1.54e-08 | 3.60e-03 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "|  83   |  81   |  249  | -3.1551e+01 | 7.72e-09 | 3.60e-03 | 0.00e+00 | 1.00e+00 |   2   |\n",
      "\n",
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 83, function evaluations: 81, CG iterations: 249, optimality: 3.60e-03, constraint violation: 0.00e+00, execution time:  6.6 s.\n",
      "⚠️ BFGS no convergió: Desired error not necessarily achieved due to precision loss.\n",
      "      optimizer    loglike   param_0   param_1   param_2       param_3  \\\n",
      "0  trust-constr  31.550821  0.054073  0.002774  0.628218  1.276469e-05   \n",
      "1     Marquardt  31.550865  0.054073  0.002774  0.628225  2.143449e-07   \n",
      "\n",
      "    param_4   param_5  \n",
      "0  0.095218  0.712056  \n",
      "1  0.095218  0.712061  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize, approx_fprime\n",
    "from scipy.stats import norm\n",
    "from scipy.linalg import solve\n",
    "\n",
    "# Log-verosimilitud ARCH(p)\n",
    "def arch_loglike(theta, y, p=4, lam=0.7):\n",
    "    mu = theta[0]\n",
    "    omega = np.exp(theta[1])\n",
    "    alphas = np.exp(theta[2:2 + p])\n",
    "\n",
    "    n = len(y)\n",
    "    e = y - mu\n",
    "\n",
    "    sigma2_bar = np.mean(e**2)\n",
    "    w = (1 - lam) * lam ** np.arange(n)\n",
    "    h0 = np.dot(w[::-1], e**2) + lam**n * sigma2_bar\n",
    "\n",
    "    h = np.empty(n)\n",
    "    h[:p] = np.full(p, h0)\n",
    "    for t in range(p, n):\n",
    "        e_lags = e[t - p:t][::-1]\n",
    "        h[t] = omega + np.dot(alphas, e_lags**2)\n",
    "        h[t] = np.maximum(h[t], 1e-8)\n",
    "\n",
    "    ll = -0.5 * np.sum(np.log(2 * np.pi) + np.log(h) + e**2 / h)\n",
    "    return -ll\n",
    "\n",
    "# Inicialización\n",
    "def init_params(y, p):\n",
    "    mu0 = np.mean(y)\n",
    "    eps = y - mu0\n",
    "    sq = eps**2\n",
    "    lags = np.column_stack([np.roll(sq, i) for i in range(1, p+1)])\n",
    "    Yv = sq[p:]\n",
    "    Xv = np.column_stack([np.ones(len(Yv)), lags[p:]])\n",
    "    params = np.linalg.lstsq(Xv, Yv, rcond=None)[0]\n",
    "    omega0 = max(params[0], 1e-6)\n",
    "    alpha0 = np.maximum(params[1:], 1e-4)\n",
    "    return np.r_[mu0, np.log(omega0), np.log(alpha0)]\n",
    "\n",
    "\n",
    "def fit_bfgs(y, p=4, lam=0.7):\n",
    "    start = init_params(y, p)\n",
    "    res = minimize(\n",
    "        fun=arch_loglike,\n",
    "        x0=start,\n",
    "        args=(y, p, lam),\n",
    "        method='BFGS',\n",
    "        options={'disp': True, 'gtol': 1e-9, 'maxiter': 2000}\n",
    "    )\n",
    "    return res\n",
    "\n",
    "\n",
    "def fit_trust(y, p=4, lam=0.7):\n",
    "    start = init_params(y, p)\n",
    "    \n",
    "    def jac(theta, y, p, lam):\n",
    "        return approx_fprime(theta, lambda th: arch_loglike(th, y, p, lam), epsilon=1e-6)\n",
    "\n",
    "    res = minimize(\n",
    "        fun=arch_loglike,\n",
    "        x0=start,\n",
    "        args=(y, p, lam),\n",
    "        method='trust-constr',\n",
    "        jac=jac,\n",
    "        bounds=None,\n",
    "        options={'verbose': 3}\n",
    "    )\n",
    "    return res\n",
    "\n",
    "\n",
    "def fit_marquardt(y, p=4, lam=0.7, max_iter=100, tol=1e-6):\n",
    "    theta = init_params(y, p)\n",
    "    n_params = len(theta)\n",
    "    I = np.eye(n_params)\n",
    "    λ = 1.0  # factor de damping\n",
    "\n",
    "    def grad(theta):\n",
    "        return approx_fprime(theta, lambda th: arch_loglike(th, y, p, lam), epsilon=1e-6)\n",
    "\n",
    "    def hess(theta):\n",
    "        eps = 1e-4\n",
    "        g0 = grad(theta)\n",
    "        H = np.zeros((n_params, n_params))\n",
    "        for i in range(n_params):\n",
    "            d = np.zeros_like(theta)\n",
    "            d[i] = eps\n",
    "            g1 = grad(theta + d)\n",
    "            H[:, i] = (g1 - g0) / eps\n",
    "        return H\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        g = grad(theta)\n",
    "        H = hess(theta)\n",
    "        try:\n",
    "            step = solve(H + λ * I, g)\n",
    "        except np.linalg.LinAlgError:\n",
    "            λ *= 10\n",
    "            continue\n",
    "\n",
    "        theta_new = theta - step\n",
    "        ll_old = arch_loglike(theta, y, p, lam)\n",
    "        ll_new = arch_loglike(theta_new, y, p, lam)\n",
    "\n",
    "        if ll_new < ll_old:\n",
    "            theta = theta_new\n",
    "            λ = max(λ / 2, 1e-6)\n",
    "        else:\n",
    "            λ *= 10\n",
    "\n",
    "        if np.linalg.norm(g) < tol:\n",
    "            break\n",
    "\n",
    "    class Result:\n",
    "        def __init__(self, x):\n",
    "            self.x = x\n",
    "            self.fun = arch_loglike(x, y, p, lam)\n",
    "            self.success = True\n",
    "            self.message = \"Converged (custom Marquardt)\"\n",
    "    return Result(theta)\n",
    "\n",
    "\n",
    "def decode_params(theta, p):\n",
    "    mu = theta[0]\n",
    "    omega = np.exp(theta[1])\n",
    "    alphas = np.exp(theta[2:2 + p])\n",
    "    return [mu, omega] + alphas.tolist()\n",
    "\n",
    "\n",
    "def summarize_optimizers(y, results_dict, p):\n",
    "    summary = []\n",
    "    for name, res in results_dict.items():\n",
    "        if not res.success:\n",
    "            print(f\"⚠️ {name} no convergió: {res.message}\")\n",
    "            continue\n",
    "        decoded = decode_params(res.x, p)\n",
    "        summary.append({\n",
    "            'optimizer': name,\n",
    "            'loglike': -res.fun,\n",
    "            **{f'param_{i}': val for i, val in enumerate(decoded)}\n",
    "        })\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "y = df_clean['y'].astype(float)\n",
    "p = 4\n",
    "\n",
    "res_bfgs = fit_bfgs(y, p)\n",
    "res_trust = fit_trust(y, p)\n",
    "res_marquardt = fit_marquardt(y, p)\n",
    "\n",
    "results = {\n",
    "    'BFGS': res_bfgs,\n",
    "    'trust-constr': res_trust,\n",
    "    'Marquardt': res_marquardt\n",
    "}\n",
    "\n",
    "df_summary = summarize_optimizers(y, results, p)\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e4e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec9fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68a070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a1cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2474d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sticks = [1,2,3,4,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bbff1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "1 2 4\n",
      "1 2 5\n",
      "1 2 10\n",
      "1 3 4\n",
      "1 3 5\n",
      "1 3 10\n",
      "1 4 3\n",
      "1 4 5\n",
      "1 4 10\n",
      "1 5 3\n",
      "1 5 4\n",
      "1 5 10\n",
      "1 10 3\n",
      "1 10 4\n",
      "1 10 5\n",
      "2 2 3\n",
      "2 2 4\n",
      "2 2 5\n",
      "2 2 10\n",
      "2 3 4\n",
      "2 3 5\n",
      "2 3 10\n",
      "2 4 3\n",
      "2 4 5\n",
      "2 4 10\n",
      "2 5 3\n",
      "2 5 4\n",
      "2 5 10\n",
      "2 10 3\n",
      "2 10 4\n",
      "2 10 5\n",
      "3 2 3\n",
      "3 2 4\n",
      "3 2 5\n",
      "3 2 10\n",
      "3 3 4\n",
      "3 3 5\n",
      "3 3 10\n",
      "3 4 3\n",
      "3 4 5\n",
      "3 4 10\n",
      "3 5 3\n",
      "3 5 4\n",
      "3 5 10\n",
      "3 10 3\n",
      "3 10 4\n",
      "3 10 5\n",
      "4 2 3\n",
      "4 2 4\n",
      "4 2 5\n",
      "4 2 10\n",
      "4 3 4\n",
      "4 3 5\n",
      "4 3 10\n",
      "4 4 3\n",
      "4 4 5\n",
      "4 4 10\n",
      "4 5 3\n",
      "4 5 4\n",
      "4 5 10\n",
      "4 10 3\n",
      "4 10 4\n",
      "4 10 5\n",
      "5 2 3\n",
      "5 2 4\n",
      "5 2 5\n",
      "5 2 10\n",
      "5 3 4\n",
      "5 3 5\n",
      "5 3 10\n",
      "5 4 3\n",
      "5 4 5\n",
      "5 4 10\n",
      "5 5 3\n",
      "5 5 4\n",
      "5 5 10\n",
      "5 10 3\n",
      "5 10 4\n",
      "5 10 5\n",
      "10 2 3\n",
      "10 2 4\n",
      "10 2 5\n",
      "10 2 10\n",
      "10 3 4\n",
      "10 3 5\n",
      "10 3 10\n",
      "10 4 3\n",
      "10 4 5\n",
      "10 4 10\n",
      "10 5 3\n",
      "10 5 4\n",
      "10 5 10\n",
      "10 10 3\n",
      "10 10 4\n",
      "10 10 5\n"
     ]
    }
   ],
   "source": [
    "for s in range(len(sticks)):\n",
    "    for i in range(1, len(sticks)): \n",
    "        for j in range(2, len(sticks)):\n",
    "            if i != j:\n",
    "                print(sticks[s], sticks[i], sticks[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
