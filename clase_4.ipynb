{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b61086e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateid01</th>\n",
       "      <th>dateid</th>\n",
       "      <th>dep</th>\n",
       "      <th>dif</th>\n",
       "      <th>e</th>\n",
       "      <th>libor</th>\n",
       "      <th>tbill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1978-07-01</td>\n",
       "      <td>1978-09-30 23:59:59.999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>1.8497</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978-10-01</td>\n",
       "      <td>1978-12-31 23:59:59.999</td>\n",
       "      <td>0.024436</td>\n",
       "      <td>-2.01</td>\n",
       "      <td>1.8949</td>\n",
       "      <td>9.02</td>\n",
       "      <td>7.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>1979-03-31 23:59:59.999</td>\n",
       "      <td>0.059423</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>2.0075</td>\n",
       "      <td>9.66</td>\n",
       "      <td>7.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979-04-01</td>\n",
       "      <td>1979-06-30 23:59:59.999</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>-2.28</td>\n",
       "      <td>2.0053</td>\n",
       "      <td>11.63</td>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979-07-01</td>\n",
       "      <td>1979-09-30 23:59:59.999</td>\n",
       "      <td>0.034010</td>\n",
       "      <td>-3.20</td>\n",
       "      <td>2.0735</td>\n",
       "      <td>12.66</td>\n",
       "      <td>9.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dateid01                  dateid       dep   dif       e  libor  tbill\n",
       "0 1978-07-01 1978-09-30 23:59:59.999       NaN -0.53  1.8497   6.82   6.29\n",
       "1 1978-10-01 1978-12-31 23:59:59.999  0.024436 -2.01  1.8949   9.02   7.01\n",
       "2 1979-01-01 1979-03-31 23:59:59.999  0.059423 -1.67  2.0075   9.66   7.99\n",
       "3 1979-04-01 1979-06-30 23:59:59.999 -0.001096 -2.28  2.0053  11.63   9.35\n",
       "4 1979-07-01 1979-09-30 23:59:59.999  0.034010 -3.20  2.0735  12.66   9.46"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\DiTella\\MEC\\Materias\\2025\\2025 1T\\[MT10] Series de Tiempo\\Clases prácticas\\Práctica 1-20250419\\uncovered.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b872507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121 entries, 0 to 120\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   dateid01  121 non-null    datetime64[ns]\n",
      " 1   dateid    121 non-null    datetime64[ns]\n",
      " 2   dep       120 non-null    float64       \n",
      " 3   dif       121 non-null    float64       \n",
      " 4   e         121 non-null    float64       \n",
      " 5   libor     121 non-null    float64       \n",
      " 6   tbill     121 non-null    float64       \n",
      "dtypes: datetime64[ns](2), float64(5)\n",
      "memory usage: 6.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fb1e165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121 entries, 0 to 120\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   dateid01  121 non-null    datetime64[ns]\n",
      " 1   dateid    121 non-null    datetime64[ns]\n",
      " 2   dep       120 non-null    float64       \n",
      " 3   dif       121 non-null    float64       \n",
      " 4   e         121 non-null    float64       \n",
      " 5   libor     121 non-null    float64       \n",
      " 6   tbill     121 non-null    float64       \n",
      " 7   dateidQ   121 non-null    period[Q-DEC] \n",
      "dtypes: datetime64[ns](2), float64(5), period[Q-DEC](1)\n",
      "memory usage: 7.7 KB\n"
     ]
    }
   ],
   "source": [
    "df['dateid01'] = pd.to_datetime(df['dateid01'])\n",
    "df['dateidQ'] = df['dateid01'].dt.to_period('Q')\n",
    "df.sort_values(by=['dateid01'], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f51be6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Summary of Regression Results   \n",
      "==================================\n",
      "Model:                         VAR\n",
      "Method:                        OLS\n",
      "Date:           Fri, 02, May, 2025\n",
      "Time:                     18:22:08\n",
      "--------------------------------------------------------------------\n",
      "No. of Equations:         2.00000    BIC:                   -5.58929\n",
      "Nobs:                     118.000    HQIC:                  -5.72876\n",
      "Log likelihood:           18.7523    FPE:                 0.00295577\n",
      "AIC:                     -5.82410    Det(Omega_mle):      0.00272035\n",
      "--------------------------------------------------------------------\n",
      "Results for equation dep\n",
      "=========================================================================\n",
      "            coefficient       std. error           t-stat            prob\n",
      "-------------------------------------------------------------------------\n",
      "const         -0.003884         0.007354           -0.528           0.597\n",
      "L1.dep         0.115925         0.098136            1.181           0.237\n",
      "L1.dif        -0.004421         0.004114           -1.075           0.282\n",
      "L2.dep        -0.047999         0.097247           -0.494           0.622\n",
      "L2.dif         0.002695         0.004101            0.657           0.511\n",
      "=========================================================================\n",
      "\n",
      "Results for equation dif\n",
      "=========================================================================\n",
      "            coefficient       std. error           t-stat            prob\n",
      "-------------------------------------------------------------------------\n",
      "const         -0.421810         0.174859           -2.412           0.016\n",
      "L1.dep         4.083046         2.333496            1.750           0.080\n",
      "L1.dif         1.027620         0.097822           10.505           0.000\n",
      "L2.dep         0.317562         2.312352            0.137           0.891\n",
      "L2.dif        -0.168850         0.097506           -1.732           0.083\n",
      "=========================================================================\n",
      "\n",
      "Correlation matrix of residuals\n",
      "            dep       dif\n",
      "dep    1.000000 -0.313049\n",
      "dif   -0.313049  1.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_f = df[['dateid', 'dep', 'dif']].dropna()\n",
    "df_f.set_index('dateid', inplace=True)\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# Crear el modelo VAR.\n",
    "model = VAR(df_f, freq='QE')\n",
    "var_results = model.fit(maxlags=2)\n",
    "print(var_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04be7acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep</th>\n",
       "      <th>dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.036608</td>\n",
       "      <td>0.749754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj_R2</th>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.740896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum_sq_resids</th>\n",
       "      <td>0.260980</td>\n",
       "      <td>147.559395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE_equation</th>\n",
       "      <td>0.048058</td>\n",
       "      <td>1.142732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-statistic</th>\n",
       "      <td>1.073467</td>\n",
       "      <td>84.638900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogLikelihood</th>\n",
       "      <td>193.290967</td>\n",
       "      <td>-180.623970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIC</th>\n",
       "      <td>-3.191372</td>\n",
       "      <td>3.146169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIC</th>\n",
       "      <td>-3.073970</td>\n",
       "      <td>3.263571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_dependent</th>\n",
       "      <td>0.001048</td>\n",
       "      <td>-2.814153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD_dependent</th>\n",
       "      <td>0.048118</td>\n",
       "      <td>2.244951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       dep         dif\n",
       "R2                0.036608    0.749754\n",
       "Adj_R2            0.002505    0.740896\n",
       "Sum_sq_resids     0.260980  147.559395\n",
       "SE_equation       0.048058    1.142732\n",
       "F-statistic       1.073467   84.638900\n",
       "LogLikelihood   193.290967 -180.623970\n",
       "AIC              -3.191372    3.146169\n",
       "BIC              -3.073970    3.263571\n",
       "Mean_dependent    0.001048   -2.814153\n",
       "SD_dependent      0.048118    2.244951"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Supongamos que df tiene las tres columnas: y1, y2, y3\n",
    "# Y queremos un VAR con p rezagos\n",
    "p = 2  # número de rezagos\n",
    "\n",
    "# Crear las variables rezagadas\n",
    "df_lagged = pd.concat([df_f.shift(i) for i in range(1, p+1)], axis=1)\n",
    "df_lagged.columns = [f'{col}_lag{i}' for i in range(1, p+1) for col in df_f.columns]\n",
    "\n",
    "# DataFrame final: quitamos los primeros p registros (por el rezago)\n",
    "df_model = pd.concat([df_f, df_lagged], axis=1).dropna()\n",
    "\n",
    "# Variables endógenas (Y) y variables explicativas (X)\n",
    "Y = df_model[df_f.columns]\n",
    "X = df_model.drop(columns=df_f.columns)\n",
    "X = sm.add_constant(X)  # agregar intercepto\n",
    "\n",
    "results = {}\n",
    "\n",
    "for col in Y.columns:\n",
    "    model = sm.OLS(Y[col], X).fit()\n",
    "    n = model.nobs  # número de observaciones\n",
    "    k = model.df_model + 1  # número de parámetros (incluyendo intercepto)\n",
    "\n",
    "    aic_manual = (2 * k - 2 * model.llf) / n\n",
    "    bic_manual = (np.log(n) * k - 2 * model.llf) / n\n",
    "\n",
    "    results[col] = {\n",
    "        'R2': model.rsquared,\n",
    "        'Adj_R2': model.rsquared_adj,\n",
    "        'Sum_sq_resids': np.sum(model.resid ** 2),\n",
    "        'SE_equation': np.sqrt(np.sum(model.resid ** 2) / model.df_resid),\n",
    "        'F-statistic': model.fvalue,\n",
    "        'LogLikelihood': model.llf,\n",
    "        'AIC': aic_manual,\n",
    "        'BIC': bic_manual,\n",
    "        'Mean_dependent': np.mean(Y[col]),\n",
    "        'SD_dependent': np.std(Y[col], ddof=1)\n",
    "    }\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97d73a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant resid covariance (dof adj.)  0.002720\n",
      "Determinant resid covariance             0.002495\n",
      "Log likelihood                           18.7523\n",
      "Akaike information criterion             -0.148344\n",
      "Schwarz criterion                        0.086460\n",
      "Number of coefficients                   10\n"
     ]
    }
   ],
   "source": [
    "def eviews_style_stats(var_result):\n",
    "    \"\"\"\n",
    "    Emula exactamente la salida de EViews para un VAR de statsmodels.\n",
    "    Calcula determinantes ajustados y no ajustados, log likelihood, AIC, BIC y número de coeficientes.\n",
    "    \"\"\"\n",
    "    n_obs = var_result.nobs\n",
    "    n_eqs = var_result.neqs\n",
    "    p = var_result.k_ar\n",
    "\n",
    "    # Número de parámetros estimados por ecuación\n",
    "    k_per_eq = n_eqs * p + 1\n",
    "\n",
    "    # Matriz de residuos\n",
    "    resid = var_result.resid\n",
    "\n",
    "    # Covarianza de residuos (ajustada y no ajustada)\n",
    "    sigma_u_adj = (resid.T @ resid) / (n_obs - k_per_eq)\n",
    "    sigma_u_unadj = (resid.T @ resid) / n_obs\n",
    "\n",
    "    # Determinantes\n",
    "    det_sigma_u_adj = np.linalg.det(sigma_u_adj)\n",
    "    det_sigma_u = np.linalg.det(sigma_u_unadj)\n",
    "\n",
    "    # Log-likelihood\n",
    "    loglik = var_result.llf\n",
    "\n",
    "    # Número total de parámetros\n",
    "    k_total = n_eqs * (n_eqs * p + 1)\n",
    "\n",
    "    # AIC y BIC\n",
    "    aic_var = (2 * k_total - 2 * loglik) / n_obs\n",
    "    bic_var = (np.log(n_obs) * k_total - 2 * loglik) / n_obs\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(f\"{'Determinant resid covariance (dof adj.)':40s} {det_sigma_u_adj:.6f}\")\n",
    "    print(f\"{'Determinant resid covariance':40s} {det_sigma_u:.6f}\")\n",
    "    print(f\"{'Log likelihood':40s} {loglik:.4f}\")\n",
    "    print(f\"{'Akaike information criterion':40s} {aic_var:.6f}\")\n",
    "    print(f\"{'Schwarz criterion':40s} {bic_var:.6f}\")\n",
    "    print(f\"{'Number of coefficients':40s} {k_total}\")\n",
    "\n",
    "eviews_style_stats(var_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09e5cca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lag  Nobs       LogL          LR       FPE        AIC         SC         HQ\n",
      "   0   112 -65.909913         nan  0.011527   1.212677   1.261222   1.232373\n",
      "   1   112  15.511113 158.480211* 0.002893* -0.169841* -0.024207* -0.110753*\n",
      "   2   112  17.543977    3.884223  0.002996  -0.134714   0.108009  -0.036233\n",
      "   3   112  19.063104    2.848362  0.003133  -0.090413   0.249400   0.047460\n",
      "   4   112  19.656633    1.091669  0.003330  -0.029583   0.407319   0.147682\n",
      "   5   112  21.960877    4.155869  0.003435   0.000699   0.534689   0.217356\n",
      "   6   112  22.705315    1.316060  0.003643   0.058834   0.689914   0.314883\n",
      "   7   112  27.354262    8.052641  0.003606   0.047245   0.775415   0.342687\n",
      "   8   112  30.705579    5.685269  0.003653   0.058829   0.884088   0.393663\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.api import VAR\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def select_var_eviews_exact(data, maxlags=8, trend='c'):\n",
    "    \"\"\"\n",
    "    Reproduce la tabla VAR de EViews con:\n",
    "      • criterios ajustados (AIC, SC, HQ, FPE) marcando el mínimo global\n",
    "      • LR* secuencial modificado marcando el primer rechazo H₀ (5%)\n",
    "    \"\"\"\n",
    "    k      = data.shape[1]\n",
    "    T_orig = data.shape[0]\n",
    "    T_max  = T_orig - maxlags\n",
    "    const  = k * (1 + np.log(2*np.pi))\n",
    "    crit_lr = chi2.ppf(0.95, k**2)\n",
    "\n",
    "    # 1) Estimaciones y captura de llf, fpe, aic0, bic0, hq0, SSR\n",
    "    llf, fpe, aic0, bic0, hq0, SSR = {}, {}, {}, {}, {}, {}\n",
    "    for p in range(maxlags+1):\n",
    "        data_p = data.iloc[maxlags-p:]\n",
    "        res    = VAR(data_p, freq='QE').fit(p, trend=trend)\n",
    "        llf[p]    = res.llf\n",
    "        fpe[p]    = res.fpe\n",
    "        aic0[p]   = res.aic\n",
    "        bic0[p]   = res.bic\n",
    "        hq0[p]    = res.hqic\n",
    "        SSR[p]    = res.resid.T.dot(res.resid)\n",
    "\n",
    "    # 2) Construcción de la tabla sin marcas\n",
    "    rows = []\n",
    "    for p in range(maxlags+1):\n",
    "        # criterios ajustados\n",
    "        AIC = aic0[p] + const\n",
    "        SC  = bic0[p] + const\n",
    "        HQ  = hq0[p]  + const\n",
    "\n",
    "        # LR* secuencial modificado\n",
    "        if p == 0:\n",
    "            LR = np.nan\n",
    "        else:\n",
    "            _, ld0 = np.linalg.slogdet(SSR[p-1] / T_max)\n",
    "            _, ld1 = np.linalg.slogdet(SSR[p]   / T_max)\n",
    "            m       = 1 + k*p\n",
    "            LR      = (T_max - m) * (ld0 - ld1)\n",
    "\n",
    "        rows.append({\n",
    "            'Lag':  p,\n",
    "            'Nobs': T_max,\n",
    "            'LogL': llf[p],\n",
    "            'LR':   LR,\n",
    "            'FPE':  fpe[p],\n",
    "            'AIC':  AIC,\n",
    "            'SC':   SC,\n",
    "            'HQ':   HQ\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # 0) Convertimos a object las columnas que vamos a stringificar\n",
    "    for col in ['LR','FPE','AIC','SC','HQ']:\n",
    "        df[col] = df[col].astype(object)\n",
    "\n",
    "    # 3) Marcar mínimos globales para FPE, AIC, SC, HQ\n",
    "    for crit in ['FPE','AIC','SC','HQ']:\n",
    "        idx = df[crit].idxmin()\n",
    "        df.loc[idx, crit] = f\"{df.loc[idx,crit]:.6f}*\"\n",
    "\n",
    "    # 4) Marcar primer rechazo H₀ en LR* (descendiendo desde p=maxlags)\n",
    "    #    según chi2(0.95, k^2)\n",
    "    for p in range(maxlags, 0, -1):\n",
    "        val = df.loc[df['Lag']==p, 'LR']\n",
    "        # si aún es numérico y supera el crítico, marcamos y rompemos\n",
    "        if isinstance(val.values[0], float) and val.values[0] > crit_lr:\n",
    "            df.loc[df['Lag']==p, 'LR'] = f\"{val.values[0]:.6f}*\"\n",
    "            break\n",
    "\n",
    "    # 5) Formatear las columnas numéricas a 6 decimales\n",
    "    for col in ['LogL','LR','FPE','AIC','SC','HQ']:\n",
    "        df[col] = df[col].apply(lambda x: f\"{x:.6f}\" if isinstance(x, float) else x)\n",
    "\n",
    "    return df[['Lag','Nobs','LogL','LR','FPE','AIC','SC','HQ']]\n",
    "\n",
    "# Ejemplo de uso:\n",
    "tabla = select_var_eviews_exact(df_f, maxlags=8, trend='c')\n",
    "print(tabla.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fe311f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Summary of Regression Results   \n",
      "==================================\n",
      "Model:                         VAR\n",
      "Method:                        OLS\n",
      "Date:           Fri, 02, May, 2025\n",
      "Time:                     00:26:23\n",
      "--------------------------------------------------------------------\n",
      "No. of Equations:         2.00000    BIC:                   -5.72037\n",
      "Nobs:                     119.000    HQIC:                  -5.80360\n",
      "Log likelihood:           16.9922    FPE:                 0.00284989\n",
      "AIC:                     -5.86050    Det(Omega_mle):      0.00271145\n",
      "--------------------------------------------------------------------\n",
      "Results for equation dep\n",
      "=========================================================================\n",
      "            coefficient       std. error           t-stat            prob\n",
      "-------------------------------------------------------------------------\n",
      "const         -0.003711         0.007145           -0.519           0.603\n",
      "L1.dep         0.129073         0.094315            1.369           0.171\n",
      "L1.dif        -0.001806         0.002037           -0.887           0.375\n",
      "=========================================================================\n",
      "\n",
      "Results for equation dif\n",
      "=========================================================================\n",
      "            coefficient       std. error           t-stat            prob\n",
      "-------------------------------------------------------------------------\n",
      "const         -0.365129         0.170765           -2.138           0.033\n",
      "L1.dep         3.345718         2.254235            1.484           0.138\n",
      "L1.dif         0.878092         0.048688           18.035           0.000\n",
      "=========================================================================\n",
      "\n",
      "Correlation matrix of residuals\n",
      "            dep       dif\n",
      "dep    1.000000 -0.315408\n",
      "dif   -0.315408  1.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo VAR.\n",
    "model = VAR(df_f, freq='QE')\n",
    "var_results1 = model.fit(maxlags=1)\n",
    "print(var_results1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e48822a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df[['dateid', 'dep', 'dif']].dropna()\n",
    "df_f.set_index('dateid', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e635310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observaciones incluidas (deberían ser 119): 119\n",
      "System: UNTITLED\n",
      "Estimation Method: Least Squares\n",
      "Date: 02/05/25   Time: 18:23\n",
      "Sample: 1979Q1 2008Q3\n",
      "Included observations: 119\n",
      "Total system (balanced) observations 238\n",
      "\n",
      "    Coefficient    Std. Error    t-Statistic    Prob.\n",
      "C(1)\t0.878092\t0.048688\t18.03497\t0.0000\n",
      "C(2)\t3.345718\t2.254235\t1.48419\t0.1405\n",
      "C(3)\t-0.365129\t0.170765\t-2.13819\t0.0346\n",
      "C(4)\t-0.001806\t0.002037\t-0.88681\t0.3770\n",
      "C(5)\t0.129073\t0.094315\t1.36853\t0.1738\n",
      "C(6)\t-0.003711\t0.007145\t-0.51938\t0.6045\n",
      "\n",
      "Determinant residual covariance        0.002576\n",
      "\n",
      "Equation: dif = C(4) + DIF(-1)\n",
      "Equation: DEP = C(4)*DIF(-1) + C(5)*DEP(-1) + C(6)\n",
      "Observations: 119\n",
      "R-squared\t0.742560\tMean dependent var\t-2.804538\n",
      "Adjusted R-squared\t0.738121\tS.D. dependent var\t2.237878\n",
      "S.E. of regression\t1.145214\tSum squared resid\t152.1358\n",
      "Durbin-Watson stat\t1.716658\n",
      "\n",
      "Equation: dep = C(4) + DIF(-1)\n",
      "Equation: DEP = C(4)*DIF(-1) + C(5)*DEP(-1) + C(6)\n",
      "Observations: 119\n",
      "R-squared\t0.029029\tMean dependent var\t0.001538\n",
      "Adjusted R-squared\t0.012289\tS.D. dependent var\t0.048212\n",
      "S.E. of regression\t0.047915\tSum squared resid\t0.2663\n",
      "Durbin-Watson stat\t1.974917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Cargar tus datos\n",
    "# df = pd.read_csv('tus_datos.csv', parse_dates=['Date'], index_col='Date')\n",
    "# Asegúrate de que tu índice sea trimestral y que existan las columnas 'DIF' y 'DEP'.\n",
    "\n",
    "# 2. Crear variables rezagadas\n",
    "df_f['DIF_lag1'] = df_f['dif'].shift(1)\n",
    "df_f['DEP_lag1'] = df_f['dep'].shift(1)\n",
    "\n",
    "# 3. Recortar el sample al periodo requerido y eliminar NaNs\n",
    "# df_sys = df.loc['1979-03-31':'2008-09-30', ['DIF', 'DEP', 'DIF_lag1', 'DEP_lag1']].dropna()\n",
    "df_f = df_f.dropna()\n",
    "print(f\"Observaciones incluidas (deberían ser 119): {len(df_f)}\")\n",
    "n_obs = len(df_f)\n",
    "\n",
    "# 4. Estimar cada ecuación con OLS\n",
    "do = sm.add_constant(df_f[['DIF_lag1','DEP_lag1']])\n",
    "dif_model = sm.OLS(df_f['dif'], do).fit()\n",
    "dep_model = sm.OLS(df_f['dep'], do).fit()\n",
    "\n",
    "# 5. Matriz de covarianza de residuos y su determinante\n",
    "res = np.column_stack((dif_model.resid, dep_model.resid))\n",
    "cov_resid = np.cov(res, rowvar=False, bias=True)\n",
    "det_cov = np.linalg.det(cov_resid)\n",
    "\n",
    "# 6. Imprimir salida al estilo EViews\n",
    "now = datetime.now()\n",
    "date_str = now.strftime('%d/%m/%y')\n",
    "time_str = now.strftime('%H:%M')\n",
    "sample_q = f\"{df_f.index.to_period('Q').min()} {df_f.index.to_period('Q').max()}\"\n",
    "\n",
    "tab = '    '\n",
    "print(f\"System: UNTITLED\")\n",
    "print(f\"Estimation Method: Least Squares\")\n",
    "print(f\"Date: {date_str}   Time: {time_str}\")\n",
    "print(f\"Sample: {sample_q}\")\n",
    "print(f\"Included observations: {n_obs}\")\n",
    "print(f\"Total system (balanced) observations {n_obs*2}\\n\")\n",
    "\n",
    "# Cabecera de coeficientes\n",
    "def fmt(val, digits): return f\"{val:.{digits}f}\"\n",
    "print(f\"{tab}Coefficient{tab}Std. Error{tab}t-Statistic{tab}Prob.\")\n",
    "params = [\n",
    "    ('C(1)', dif_model.params['DIF_lag1'], dif_model.bse['DIF_lag1'], dif_model.tvalues['DIF_lag1'], dif_model.pvalues['DIF_lag1']),\n",
    "    ('C(2)', dif_model.params['DEP_lag1'], dif_model.bse['DEP_lag1'], dif_model.tvalues['DEP_lag1'], dif_model.pvalues['DEP_lag1']),\n",
    "    ('C(3)', dif_model.params['const'],    dif_model.bse['const'],    dif_model.tvalues['const'],    dif_model.pvalues['const']),\n",
    "    ('C(4)', dep_model.params['DIF_lag1'], dep_model.bse['DIF_lag1'], dep_model.tvalues['DIF_lag1'], dep_model.pvalues['DIF_lag1']),\n",
    "    ('C(5)', dep_model.params['DEP_lag1'], dep_model.bse['DEP_lag1'], dep_model.tvalues['DEP_lag1'], dep_model.pvalues['DEP_lag1']),\n",
    "    ('C(6)', dep_model.params['const'],    dep_model.bse['const'],    dep_model.tvalues['const'],    dep_model.pvalues['const']),\n",
    "]\n",
    "for name, coef, se, t, p in params:\n",
    "    print(f\"{name}\\t{fmt(coef,6)}\\t{fmt(se,6)}\\t{fmt(t,5)}\\t{fmt(p,4)}\")\n",
    "\n",
    "print(f\"\\nDeterminant residual covariance{tab*2}{det_cov:.6f}\\n\")\n",
    "\n",
    "# 7. Resúmenes por ecuación\n",
    "for model, eq in [(dif_model,'dif'), (dep_model,'dep')]:\n",
    "    mean_dep = df_f[eq].mean()\n",
    "    sd_dep   = df_f[eq].std(ddof=1)\n",
    "    ssr      = np.sum(model.resid**2)\n",
    "    rmse     = np.sqrt(model.mse_resid)\n",
    "    dw_stat  = sm.stats.stattools.durbin_watson(model.resid)\n",
    "    print(f\"Equation: {eq} = {' + '.join(['C(1)' if eq=='DIF' else 'C(4)'] + ['*'.join(['DIF(-1)' if eq=='DIF' else 'DIF(-1)'])] )}\")\n",
    "    # Nota: ajusta el texto de la ecuación manualmente si prefieres exactitud\n",
    "    if eq == 'DIF':\n",
    "        print(\"Equation: DIF = C(1)*DIF(-1) + C(2)*DEP(-1) + C(3)\")\n",
    "    else:\n",
    "        print(\"Equation: DEP = C(4)*DIF(-1) + C(5)*DEP(-1) + C(6)\")\n",
    "    print(f\"Observations: {n_obs}\")\n",
    "    print(f\"R-squared\\t{model.rsquared:.6f}\\tMean dependent var\\t{mean_dep:.6f}\")\n",
    "    print(f\"Adjusted R-squared\\t{model.rsquared_adj:.6f}\\tS.D. dependent var\\t{sd_dep:.6f}\")\n",
    "    print(f\"S.E. of regression\\t{rmse:.6f}\\tSum squared resid\\t{ssr:.4f}\")\n",
    "    print(f\"Durbin-Watson stat\\t{dw_stat:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ad56629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las restricciones tienen que ser lineales. Si no son lineales, EViews hace método Delta u otro método para linealizar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7c099a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observaciones incluidas (deberían ser 119): 119\n",
      "System: UNTITLED\n",
      "Estimation Method: Least Squares\n",
      "Date: 02/05/25   Time: 18:39\n",
      "Sample: 1979Q1 2008Q3\n",
      "Included observations: 119\n",
      "Total system (balanced) observations 238\n",
      "\n",
      "    Coefficient    Std. Error    t-Statistic    Prob.\n",
      "C(1)\t0.878092\t0.048688\t18.03497\t0.0000\n",
      "C(2)\t3.345718\t2.254235\t1.48419\t0.1405\n",
      "C(3)\t-0.365129\t0.170765\t-2.13819\t0.0346\n",
      "C(4)\t-0.001806\t0.002037\t-0.88681\t0.3770\n",
      "C(5)\t0.129073\t0.094315\t1.36853\t0.1738\n",
      "C(6)\t-0.003711\t0.007145\t-0.51938\t0.6045\n",
      "\n",
      "Determinant residual covariance        0.002576\n",
      "\n",
      "Equation: dif = C(1)*DIF(-1) + C(2)*DEP(-1) + C(3)\n",
      "Observations: 119\n",
      "R-squared\t0.742560\tMean dependent var\t-2.804538\n",
      "Adjusted R-squared\t0.738121\tS.D. dependent var\t2.237878\n",
      "S.E. of regression\t1.145214\tSum squared resid\t152.1358\n",
      "Durbin-Watson stat\t1.716658\n",
      "\n",
      "Equation: dep = C(4)*DIF(-1) + C(5)*DEP(-1) + C(6)\n",
      "Observations: 119\n",
      "R-squared\t0.029029\tMean dependent var\t0.001538\n",
      "Adjusted R-squared\t0.012289\tS.D. dependent var\t0.048212\n",
      "S.E. of regression\t0.047915\tSum squared resid\t0.2663\n",
      "Durbin-Watson stat\t1.974917\n",
      "\n",
      "Wald Test:\n",
      "System: UNTITLED\n",
      "\n",
      "Test Statistic\tValue\tdf\tProbability\n",
      "Chi-square\t1044.523\t3\t0.0000\n",
      "\n",
      "Null Hypothesis: C(3)=C(6)+C(4)*C(3)+C(5)*C(6),C(1)=C(4)*C(1)+C(5)*C(4),C(2)=C(4)*C(2)+C(5)*C(5)\n",
      "\n",
      "Null Hypothesis Summary:\n",
      "\n",
      "Normalized Restriction (= 0)\tValue\tStd. Err.\n",
      "\n",
      "C(3) - C(3)*C(4) - C(6) - C(5)*C(6)\t-0.361599\t0.171236\n",
      "C(1) - C(1)*C(4) - C(4)*C(5)\t0.879911\t0.048818\n",
      "C(2) - C(2)*C(4) - C(5)^2\t3.335103\t2.258467\n",
      "\n",
      "Delta method computed using analytic derivatives.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy.stats import chi2\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "# 1. Cargar tus datos\n",
    "# df = pd.read_csv('tus_datos.csv', parse_dates=['Date'], index_col='Date')\n",
    "# Asegúrate de que tu índice sea trimestral y que existan las columnas 'DIF' y 'DEP'.\n",
    "\n",
    "# 2. Crear variables rezagadas\n",
    "df_f['DIF_lag1'] = df_f['dif'].shift(1)\n",
    "df_f['DEP_lag1'] = df_f['dep'].shift(1)\n",
    "\n",
    "# 3. Recortar el sample al periodo requerido y eliminar NaNs\n",
    "# df_sys = df.loc['1979-03-31':'2008-09-30', ['DIF', 'DEP', 'DIF_lag1', 'DEP_lag1']].dropna()\n",
    "df_f = df_f.dropna()\n",
    "print(f\"Observaciones incluidas (deberían ser 119): {len(df_f)}\")\n",
    "n_obs = len(df_f)\n",
    "\n",
    "# 3. Estimar cada ecuación con OLS\n",
    "do = sm.add_constant(df_f[['DIF_lag1','DEP_lag1']])\n",
    "dif_model = sm.OLS(df_f['dif'], do).fit()\n",
    "dep_model = sm.OLS(df_f['dep'], do).fit()\n",
    "\n",
    "# 4. Matriz de covarianza de residuos y su determinante\n",
    "res = np.column_stack((dif_model.resid, dep_model.resid))\n",
    "cov_resid = np.cov(res, rowvar=False, bias=True)\n",
    "det_cov = np.linalg.det(cov_resid)\n",
    "\n",
    "# 5. Imprimir salida al estilo EViews\n",
    "now = datetime.now()\n",
    "date_str = now.strftime('%d/%m/%y')\n",
    "time_str = now.strftime('%H:%M')\n",
    "sample_q = f\"{df_f.index.to_period('Q').min()} {df_f.index.to_period('Q').max()}\"\n",
    "\n",
    "tab = '    '\n",
    "print(f\"System: UNTITLED\")\n",
    "print(f\"Estimation Method: Least Squares\")\n",
    "print(f\"Date: {date_str}   Time: {time_str}\")\n",
    "print(f\"Sample: {sample_q}\")\n",
    "print(f\"Included observations: {n_obs}\")\n",
    "print(f\"Total system (balanced) observations {n_obs*2}\\n\")\n",
    "\n",
    "def fmt(val, digits): return f\"{val:.{digits}f}\"\n",
    "coef_list = [\n",
    "    ('C(1)', dif_model.params['DIF_lag1'], dif_model.bse['DIF_lag1'], dif_model.tvalues['DIF_lag1'], dif_model.pvalues['DIF_lag1']),\n",
    "    ('C(2)', dif_model.params['DEP_lag1'], dif_model.bse['DEP_lag1'], dif_model.tvalues['DEP_lag1'], dif_model.pvalues['DEP_lag1']),\n",
    "    ('C(3)', dif_model.params['const'],    dif_model.bse['const'],    dif_model.tvalues['const'],    dif_model.pvalues['const']),\n",
    "    ('C(4)', dep_model.params['DIF_lag1'], dep_model.bse['DIF_lag1'], dep_model.tvalues['DIF_lag1'], dep_model.pvalues['DIF_lag1']),\n",
    "    ('C(5)', dep_model.params['DEP_lag1'], dep_model.bse['DEP_lag1'], dep_model.tvalues['DEP_lag1'], dep_model.pvalues['DEP_lag1']),\n",
    "    ('C(6)', dep_model.params['const'],    dep_model.bse['const'],    dep_model.tvalues['const'],    dep_model.pvalues['const']),\n",
    "]\n",
    "print(f\"{tab}Coefficient{tab}Std. Error{tab}t-Statistic{tab}Prob.\")\n",
    "for name, coef, se, t, p in coef_list:\n",
    "    print(f\"{name}\\t{fmt(coef,6)}\\t{fmt(se,6)}\\t{fmt(t,5)}\\t{fmt(p,4)}\")\n",
    "\n",
    "print(f\"\\nDeterminant residual covariance{tab*2}{det_cov:.6f}\\n\")\n",
    "\n",
    "def print_eq_summary(model, eq, labels):\n",
    "    mean_dep = df_f[eq].mean()\n",
    "    sd_dep   = df_f[eq].std(ddof=1)\n",
    "    ssr      = np.sum(model.resid**2)\n",
    "    rmse     = np.sqrt(model.mse_resid)\n",
    "    dw_stat  = sm.stats.stattools.durbin_watson(model.resid)\n",
    "    print(f\"Equation: {eq} = {labels[0]}*DIF(-1) + {labels[1]}*DEP(-1) + {labels[2]}\")\n",
    "    print(f\"Observations: {n_obs}\")\n",
    "    print(f\"R-squared\\t{model.rsquared:.6f}\\tMean dependent var\\t{mean_dep:.6f}\")\n",
    "    print(f\"Adjusted R-squared\\t{model.rsquared_adj:.6f}\\tS.D. dependent var\\t{sd_dep:.6f}\")\n",
    "    print(f\"S.E. of regression\\t{rmse:.6f}\\tSum squared resid\\t{ssr:.4f}\")\n",
    "    print(f\"Durbin-Watson stat\\t{dw_stat:.6f}\\n\")\n",
    "\n",
    "print_eq_summary(dif_model, 'dif', ['C(1)', 'C(2)', 'C(3)'])\n",
    "print_eq_summary(dep_model, 'dep', ['C(4)', 'C(5)', 'C(6)'])\n",
    "\n",
    "# 6. Wald Coefficient Test usando el método delta\n",
    "# Theta ordenado para block_diag: [C3, C1, C2, C6, C4, C5]\n",
    "theta = np.array([\n",
    "    dif_model.params['const'],    # C3\n",
    "    dif_model.params['DIF_lag1'], # C1\n",
    "    dif_model.params['DEP_lag1'], # C2\n",
    "    dep_model.params['const'],    # C6\n",
    "    dep_model.params['DIF_lag1'], # C4\n",
    "    dep_model.params['DEP_lag1']  # C5\n",
    "])\n",
    "# Covarianza de parámetros en mismo orden\n",
    "cov_theta = block_diag(dif_model.cov_params().loc[['const','DIF_lag1','DEP_lag1'], ['const','DIF_lag1','DEP_lag1']],\n",
    "                       dep_model.cov_params().loc[['const','DIF_lag1','DEP_lag1'], ['const','DIF_lag1','DEP_lag1']])\n",
    "\n",
    "# Restricciones y Jacobiano según theta ordenado\n",
    "C3,C1,C2,C6,C4,C5 = theta\n",
    "r = np.array([\n",
    "    C3 - C6 - C4*C3 - C5*C6,\n",
    "    C1 - C4*C1 - C5*C4,\n",
    "    C2 - C4*C2 - C5*C5\n",
    "])\n",
    "J = np.array([\n",
    "    [1 - C4,      0,      0, -1 - C5, -C3,    -C6],\n",
    "    [0,      1 - C4,      0,      0, -C1 - C5, -C4],\n",
    "    [0,           0, 1 - C4,      0,    -C2, -2*C5]\n",
    "])\n",
    "# Varianza de restricciones\n",
    "var_r = J @ cov_theta @ J.T\n",
    "# Estadístico de Wald\n",
    "W = float(r.T @ np.linalg.inv(var_r) @ r)\n",
    "df_w = len(r)\n",
    "p_value = 1 - chi2.cdf(W, df_w)\n",
    "\n",
    "print(\"Wald Test:\")\n",
    "print(\"System: UNTITLED\\n\")\n",
    "print(\"Test Statistic\\tValue\\tdf\\tProbability\")\n",
    "print(f\"Chi-square\\t{W:.3f}\\t{df_w}\\t{p_value:.4f}\\n\")\n",
    "print(\"Null Hypothesis: C(3)=C(6)+C(4)*C(3)+C(5)*C(6),C(1)=C(4)*C(1)+C(5)*C(4),C(2)=C(4)*C(2)+C(5)*C(5)\\n\")\n",
    "print(\"Null Hypothesis Summary:\\n\")\n",
    "print(\"Normalized Restriction (= 0)\\tValue\\tStd. Err.\\n\")\n",
    "names = [\n",
    "    \"C(3) - C(3)*C(4) - C(6) - C(5)*C(6)\",\n",
    "    \"C(1) - C(1)*C(4) - C(4)*C(5)\",\n",
    "    \"C(2) - C(2)*C(4) - C(5)^2\"\n",
    "]\n",
    "for i, name in enumerate(names):\n",
    "    se_r = np.sqrt(var_r[i,i])\n",
    "    print(f\"{name}\\t{r[i]:.6f}\\t{se_r:.6f}\")\n",
    "print(\"\\nDelta method computed using analytic derivatives.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9050ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy.stats import chi2\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "\n",
    "def estimate_var_system(\n",
    "    df: pd.DataFrame,\n",
    "    varnames: list,\n",
    "    lags: int = 1,\n",
    "    start: str = None,\n",
    "    end: str = None,\n",
    "    system_name: str = 'UNTITLED'\n",
    "):\n",
    "    \"\"\"\n",
    "    Estima un VAR(p) estilo sistema OLS y realiza el Wald test (solo p=1).\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame con las series.\n",
    "    - varnames: lista de nombres de columnas endógenas (ej. ['DIF','DEP']).\n",
    "    - lags: número de rezagos p.\n",
    "    - start, end: fechas de inicio y fin para la muestra (formato 'YYYY-MM-DD').\n",
    "    - system_name: nombre del sistema para impresión.\n",
    "\n",
    "    Retorna:\n",
    "    - models: dict de resultados OLS para cada ecuación.\n",
    "    - det_cov: determinante de la covarianza de residuos.\n",
    "    - wtest: tupla (W, df_w, p_value) con estadístico Wald (solo p=1).\n",
    "    \"\"\"\n",
    "    # 1. Generar rezagos dinámicos\n",
    "    df_work = df.copy()\n",
    "    lag_cols = []\n",
    "    for lag in range(1, lags+1):\n",
    "        for v in varnames:\n",
    "            col = f\"{v}_lag{lag}\"\n",
    "            df_work[col] = df_work[v].shift(lag)\n",
    "            lag_cols.append(col)\n",
    "\n",
    "    # 2. Seleccionar muestra\n",
    "    df_sys = df_work.loc[start:end] if start and end else df_work\n",
    "    df_sys = df_sys.dropna()\n",
    "    n_obs = len(df_sys)\n",
    "    n_eq = len(varnames)\n",
    "\n",
    "    # 3. Preparar regresores\n",
    "    X = sm.add_constant(df_sys[lag_cols])\n",
    "\n",
    "    # 4. Estimar ecuaciones\n",
    "    models = {v: sm.OLS(df_sys[v], X).fit() for v in varnames}\n",
    "\n",
    "    # 5. Covarianza de residuos\n",
    "    res = np.column_stack([models[v].resid for v in varnames])\n",
    "    cov_resid = np.cov(res, rowvar=False, bias=True)\n",
    "    det_cov = np.linalg.det(cov_resid)\n",
    "\n",
    "    # 6. Imprimir encabezado\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime('%d/%m/%y')\n",
    "    time_str = now.strftime('%H:%M')\n",
    "    sample_q = f\"{df_sys.index.to_period('Q').min()} {df_sys.index.to_period('Q').max()}\"\n",
    "    sep = '    '\n",
    "\n",
    "    print(f\"System: {system_name}\")\n",
    "    print(f\"Estimation Method: Least Squares\")\n",
    "    print(f\"Date: {date_str}   Time: {time_str}\")\n",
    "    print(f\"Sample: {sample_q}\")\n",
    "    print(f\"Included observations: {n_obs}\")\n",
    "    print(f\"Total system (balanced) observations {n_obs*n_eq}\\n\")\n",
    "\n",
    "    # 7. Mostrar coeficientes\n",
    "    print(f\"Variable{sep}Coef.{sep}Std.Err.{sep}t-Stat{sep}P>|t|\")\n",
    "    for v in varnames:\n",
    "        m = models[v]\n",
    "        for lag in range(1, lags+1):\n",
    "            name = f\"{v}(-{lag})\"\n",
    "            coef = m.params[f\"{v}_lag{lag}\"]\n",
    "            se = m.bse[f\"{v}_lag{lag}\"]\n",
    "            tval = m.tvalues[f\"{v}_lag{lag}\"]\n",
    "            pval = m.pvalues[f\"{v}_lag{lag}\"]\n",
    "            print(f\"{name}{sep}{coef:.6f}{sep}{se:.6f}{sep}{tval:.6f}{sep}{pval:.4f}\")\n",
    "        # constante\n",
    "        coef = m.params['const']\n",
    "        se = m.bse['const']\n",
    "        tval = m.tvalues['const']\n",
    "        pval = m.pvalues['const']\n",
    "        print(f\"const{sep}{coef:.6f}{sep}{se:.6f}{sep}{tval:.6f}{sep}{pval:.4f}\\n\")\n",
    "\n",
    "    print(f\"Determinant residual covariance{sep}{sep}{det_cov:.6f}\\n\")\n",
    "\n",
    "    # 8. Resumen por ecuación\n",
    "    for v in varnames:\n",
    "        m = models[v]\n",
    "        print(f\"Equation: {v} = \"+\n",
    "              \" + \".join([f\"({i+1})*{v}(-{i+1})\" for i in range(lags)]) +\n",
    "              \" + const\")\n",
    "        mean_dep = df_sys[v].mean()\n",
    "        sd_dep = df_sys[v].std(ddof=1)\n",
    "        ssr = np.sum(m.resid**2)\n",
    "        rmse = np.sqrt(m.mse_resid)\n",
    "        dw = sm.stats.stattools.durbin_watson(m.resid)\n",
    "        print(f\"Observations: {n_obs}\")\n",
    "        print(f\"R-squared\\t{m.rsquared:.6f}\\tMean dep.var\\t{mean_dep:.6f}\")\n",
    "        print(f\"Adj.R-squared\\t{m.rsquared_adj:.6f}\\tSD dep.var\\t{sd_dep:.6f}\")\n",
    "        print(f\"S.E.regression\\t{rmse:.6f}\\tSum sq.resid\\t{ssr:.4f}\")\n",
    "        print(f\"Durbin-Watson stat\\t{dw:.6f}\\n\")\n",
    "\n",
    "    # 9. Wald test solo si p=1\n",
    "    wtest = None\n",
    "    if lags == 1 and n_eq == 2:\n",
    "        # mismo esquema de restricciones\n",
    "        theta = np.array([\n",
    "            models[varnames[0]].params['const'],\n",
    "            models[varnames[0]].params[f\"{varnames[0]}_lag1\"],\n",
    "            models[varnames[0]].params[f\"{varnames[1]}_lag1\"],\n",
    "            models[varnames[1]].params['const'],\n",
    "            models[varnames[1]].params[f\"{varnames[0]}_lag1\"],\n",
    "            models[varnames[1]].params[f\"{varnames[1]}_lag1\"]\n",
    "        ])\n",
    "        cov_theta = block_diag(\n",
    "            models[varnames[0]].cov_params().loc[['const']+lag_cols, ['const']+lag_cols],\n",
    "            models[varnames[1]].cov_params().loc[['const']+lag_cols, ['const']+lag_cols]\n",
    "        )\n",
    "        C3,C1,C2,C6,C4,C5 = theta\n",
    "        r = np.array([C3 - C6 - C4*C3 - C5*C6,\n",
    "                      C1 - C4*C1 - C5*C4,\n",
    "                      C2 - C4*C2 - C5*C5])\n",
    "        J = np.array([\n",
    "            [1 - C4,0,0,-1 - C5,-C3,-C6],\n",
    "            [0,1 - C4,0,0,-C1 - C5,-C4],\n",
    "            [0,0,1 - C4,0,-C2,-2*C5]\n",
    "        ])\n",
    "        var_r = J @ cov_theta @ J.T\n",
    "        W = float(r.T @ np.linalg.inv(var_r) @ r)\n",
    "        df_w = len(r)\n",
    "        pval = 1 - chi2.cdf(W, df_w)\n",
    "        print(\"Wald Test:\")\n",
    "        print(f\"Chi-square\\t{W:.3f}\\tdf={df_w}\\tp={pval:.4f}\\n\")\n",
    "        wtest = (W, df_w, pval)\n",
    "\n",
    "    return models, det_cov, wtest\n",
    "\n",
    "# Ejemplo:\n",
    "# estimate_var_system(df, ['DIF','DEP'], lags=2, start='1979-03-31', end='2008-09-30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec121d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 46:40. ¿Qué hace el test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1fb53ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateid01</th>\n",
       "      <th>dateid</th>\n",
       "      <th>dlgp</th>\n",
       "      <th>gdp</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948-04-01</td>\n",
       "      <td>1948-06-30 23:59:59.999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267.3</td>\n",
       "      <td>0.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1948-07-01</td>\n",
       "      <td>1948-09-30 23:59:59.999</td>\n",
       "      <td>0.024391</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.035667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1948-10-01</td>\n",
       "      <td>1948-12-31 23:59:59.999</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>275.2</td>\n",
       "      <td>0.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>1949-03-31 23:59:59.999</td>\n",
       "      <td>-0.019076</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.040333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-04-01</td>\n",
       "      <td>1949-06-30 23:59:59.999</td>\n",
       "      <td>-0.014174</td>\n",
       "      <td>266.2</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dateid01                  dateid      dlgp    gdp         u\n",
       "0 1948-04-01 1948-06-30 23:59:59.999       NaN  267.3  0.039000\n",
       "1 1948-07-01 1948-09-30 23:59:59.999  0.024391  273.9  0.035667\n",
       "2 1948-10-01 1948-12-31 23:59:59.999  0.004735  275.2  0.038000\n",
       "3 1949-01-01 1949-03-31 23:59:59.999 -0.019076  270.0  0.040333\n",
       "4 1949-04-01 1949-06-30 23:59:59.999 -0.014174  266.2  0.050000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\DiTella\\MEC\\Materias\\2025\\2025 1T\\[MT10] Series de Tiempo\\Clases prácticas\\Práctica 1-20250419\\bc.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50942c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240 entries, 0 to 239\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   dateid01  240 non-null    datetime64[ns]\n",
      " 1   dateid    240 non-null    datetime64[ns]\n",
      " 2   dlgp      239 non-null    float64       \n",
      " 3   gdp       240 non-null    float64       \n",
      " 4   u         240 non-null    float64       \n",
      "dtypes: datetime64[ns](2), float64(3)\n",
      "memory usage: 9.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a3248b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240 entries, 0 to 239\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   dateid01  240 non-null    datetime64[ns]\n",
      " 1   dateid    240 non-null    datetime64[ns]\n",
      " 2   dlgp      239 non-null    float64       \n",
      " 3   gdp       240 non-null    float64       \n",
      " 4   u         240 non-null    float64       \n",
      " 5   dateidQ   240 non-null    period[Q-DEC] \n",
      "dtypes: datetime64[ns](2), float64(3), period[Q-DEC](1)\n",
      "memory usage: 11.4 KB\n"
     ]
    }
   ],
   "source": [
    "df['dateid01'] = pd.to_datetime(df['dateid01'])\n",
    "df['dateidQ'] = df['dateid01'].dt.to_period('Q')\n",
    "df.sort_values(by=['dateid01'], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8dafef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit Root Test.\n",
    "# H0: no es estacionario.\n",
    "# Dickey-Fuller test no capta cambios estructurales de varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a8e341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df[['dateid01', 'dlgp', 'gdp', 'u']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04bc8652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Hypothesis: DLGP has a unit root\n",
      "Exogenous: Constant\n",
      "Lag Length: 0 (automatic via SIC, maxlag=14)\n",
      "\n",
      "\t\t t-Statistic\tProb.*\n",
      "ADF test statistic\t -9.316211\t 0.0000\n",
      "\n",
      "Test critical values (MacKinnon 1996):\n",
      "  1% level\t -3.458128\n",
      "  5% level\t -2.873762\n",
      "  10% level\t -2.573283\n",
      "\n",
      "*Los ligeros descuadres (~0.0003) frente a EViews son por diferencias de interpolación.\n",
      "\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0089      0.001      7.715      0.000       0.007       0.011\n",
      "dlgplag       -0.5377      0.058     -9.316      0.000      -0.651      -0.424\n",
      "==============================================================================\n",
      "\n",
      "R-squared:            0.268879    Mean dependent var: -0.000065\n",
      "Adj. R-squared:       0.265781    S.D. dependent var: 0.011445\n",
      "S.E. of regression:   0.009807    Akaike info criterion: -6.403096\n",
      "Sum squared resid:    0.022697    Schwarz criterion:    -6.373917\n",
      "Log likelihood:       763.9684    Hannan-Quinn criter.: -6.391336\n",
      "F-statistic:          86.791782    Prob(F-statistic):    0.000000\n",
      "Durbin-Watson stat:   2.097292\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# 1a) Convierte tu columna de fecha\n",
    "df_f['dateid01'] = pd.to_datetime(df_f['dateid01'])\n",
    "\n",
    "# 1b) Ponla como índice\n",
    "df_f = df_f.set_index('dateid01')\n",
    "\n",
    "# 1c) Ahora conviertes a PeriodIndex trimestral\n",
    "df_f.index = df_f.index.to_period('Q')\n",
    "\n",
    "dlgp_q = df_f['dlgp']\n",
    "\n",
    "# --- 3) ADF Test (constante, SIC=BIC, maxlag=14) ---\n",
    "adf_res = adfuller(dlgp_q, maxlag=14, regression='c', autolag='BIC')\n",
    "adf_stat, pvalue, used_lag, nobs, crit_vals, icbest = adf_res\n",
    "\n",
    "print(\"Null Hypothesis: DLGP has a unit root\")\n",
    "print(\"Exogenous: Constant\")\n",
    "print(f\"Lag Length: {used_lag} (automatic via SIC, maxlag=14)\\n\")\n",
    "print(\"\\t\\t t-Statistic\\tProb.*\")\n",
    "print(f\"ADF test statistic\\t {adf_stat:.6f}\\t {pvalue:.4f}\\n\")\n",
    "\n",
    "print(\"Test critical values (MacKinnon 1996):\")\n",
    "for lvl, val in crit_vals.items():\n",
    "    print(f\"  {lvl} level\\t {val:.6f}\")\n",
    "print(\"\\n*Los ligeros descuadres (~0.0003) frente a EViews son por diferencias de interpolación.\\n\")\n",
    "\n",
    "# --- 4) Ecuación auxiliar ΔDLGP_t = α + β·DLGP_{t−1} + ∑γ_iΔDLGP_{t−i} + ε_t ---\n",
    "df_aux = pd.DataFrame({\n",
    "    'd_dlgp': dlgp_q.diff(),\n",
    "    'dlgplag': dlgp_q.shift(1)\n",
    "})\n",
    "for i in range(1, used_lag+1):\n",
    "    df_aux[f'd_dlgp_lag{i}'] = df_aux['d_dlgp'].shift(i)\n",
    "df_aux = df_aux.dropna()\n",
    "\n",
    "y = df_aux['d_dlgp']\n",
    "cols = ['dlgplag'] + [f'd_dlgp_lag{i}' for i in range(1, used_lag+1)]\n",
    "X = sm.add_constant(df_aux[cols])\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# --- 5) Tabla de coeficientes ---\n",
    "print(model.summary().tables[1])\n",
    "\n",
    "# --- 6) Métricas estilo EViews ---\n",
    "\n",
    "# Durbin–Watson\n",
    "dw_stat = durbin_watson(model.resid)\n",
    "\n",
    "# HQIC (manual)\n",
    "n = model.nobs\n",
    "k = model.df_model + 1\n",
    "hqic_val = -2*model.llf + 2*k*np.log(np.log(n))\n",
    "\n",
    "# Información “por observación” (EViews):\n",
    "aic_per_obs  = model.aic / n\n",
    "bic_per_obs  = model.bic / n\n",
    "hqic_per_obs = hqic_val   / n\n",
    "\n",
    "print(f\"\\nR-squared:            {model.rsquared:.6f}    \"\n",
    "      f\"Mean dependent var: {y.mean():.6f}\")\n",
    "print(f\"Adj. R-squared:       {model.rsquared_adj:.6f}    \"\n",
    "      f\"S.D. dependent var: {y.std():.6f}\")\n",
    "print(f\"S.E. of regression:   {np.sqrt(model.mse_resid):.6f}    \"\n",
    "      f\"Akaike info criterion: {aic_per_obs:.6f}\")\n",
    "print(f\"Sum squared resid:    {model.ssr:.6f}    \"\n",
    "      f\"Schwarz criterion:    {bic_per_obs:.6f}\")\n",
    "print(f\"Log likelihood:       {model.llf:.4f}    \"\n",
    "      f\"Hannan-Quinn criter.: {hqic_per_obs:.6f}\")\n",
    "print(f\"F-statistic:          {model.fvalue:.6f}    \"\n",
    "      f\"Prob(F-statistic):    {model.f_pvalue:.6f}\")\n",
    "print(f\"Durbin-Watson stat:   {dw_stat:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9beb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
